{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946e6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, Model, Sequential, backend, optimizers, config\n",
    "from tensorflow.keras.layers import Input, LeakyReLU\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "config.enable_unsafe_deserialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f14297",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 93\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95cb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_cnn(n_pieces):\n",
    "    # Use Input layer to define the input shape\n",
    "    inputs = Input(shape=(n_pieces,8, 8))  \n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6d0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_input_model(n_pieces):\n",
    "    inputs = Input(shape=(n_pieces, 8, 8))\n",
    "    base_cnn = create_base_cnn(n_pieces) \n",
    "    x = base_cnn(inputs) \n",
    "    x = layers.Dense(64)(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.Dense(1, activation='tanh')(x) # Output between -1 and 1\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba3424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairwise_model(version, n_pieces):\n",
    "    base_cnn = create_base_cnn(n_pieces) \n",
    "    input_a = Input(shape=(n_pieces,8, 8)) \n",
    "    input_b = Input(shape=(n_pieces,8, 8))\n",
    "\n",
    "    encoded_a = base_cnn(input_a)\n",
    "    encoded_b = base_cnn(input_b)\n",
    "\n",
    "    diff = layers.Subtract()([encoded_a, encoded_b])\n",
    "    mult = layers.Multiply()([encoded_a, encoded_b])\n",
    "    merged = layers.Concatenate()([diff, mult])\n",
    "\n",
    "    x = layers.Dense(128)(merged)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.Dense(32)(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "\n",
    "    if version == \"Regression\":\n",
    "        output = layers.Dense(1, activation='tanh')(x) #Output between -1 and 1 \n",
    "        loss = 'mse'\n",
    "        metrics = ['mse']\n",
    "    elif version == \"Classification\":\n",
    "        output = layers.Dense(3, activation='softmax')(x)\n",
    "        loss = SparseCategoricalCrossentropy()\n",
    "        metrics = ['accuracy']\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown version: {version}\")\n",
    "\n",
    "    model = Model(inputs=[input_a, input_b], outputs=output)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0509f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_v1(X1, X2, y_true):\n",
    "    # Finds the best threshold by maximizing accuracy\n",
    "    best_threshold, best_score = None, 0\n",
    "\n",
    "    thresholds = np.linspace(0, 0.05, 200)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = np.where(np.abs(X1 - X2) < threshold, 0, np.where(X1 > X2, 1, 2))\n",
    "        score = accuracy_score(y_true, y_pred)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c7f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_thresholds_v2(predictions, labels):\n",
    "    # Finds the best threshold1 and threshold2 using a grid search by maximizing accuracy\n",
    "    thresholds1 = np.linspace(-0.8, 0, 200)\n",
    "    thresholds2 = np.linspace(0, 0.8, 200)\n",
    "\n",
    "    best_t1, best_t2, best_acc = None, None, 0\n",
    "\n",
    "    # Vectorized grid search\n",
    "    T1, T2 = np.meshgrid(thresholds1, thresholds2)\n",
    "    valid = T1 < T2\n",
    "    T1, T2 = T1[valid], T2[valid]\n",
    "\n",
    "    for t1, t2 in zip(T1, T2):\n",
    "        predicted_labels = np.where(predictions > t2, 2, np.where(predictions < t1, 1, 0))\n",
    "        acc = accuracy_score(labels, predicted_labels)\n",
    "        if acc > best_acc:\n",
    "            best_t1, best_t2, best_acc = t1, t2, acc\n",
    "\n",
    "    return best_t1, best_t2, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f2d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_post_nn(n):\n",
    "    model = Sequential([\n",
    "        layers.Input(shape=(n,)),\n",
    "        layers.Dense(8),\n",
    "        layers.LeakyReLU(negative_slope=0.1),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=lr),\n",
    "        loss=SparseCategoricalCrossentropy(),  \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647ee8c",
   "metadata": {},
   "source": [
    "**FOR ALL MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81344762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 64, 128, 256, 512]\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [int(32*(2**i)) for i in range(5)]\n",
    "print(batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a28f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, X, y, epochs_per_batch=5, acc=False):\n",
    "    hist = {'loss': [],'val_loss': []}  \n",
    "    if acc:\n",
    "        hist['accuracy'] = []\n",
    "        hist['val_accuracy'] = []\n",
    "         \n",
    "    # EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5, \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    for n, batch_size in enumerate(batch_sizes):\n",
    "        print(f\"Training with batch size: {batch_size}, epochs {n*epochs_per_batch+1} to {(n+1)*epochs_per_batch}\")\n",
    "        # Train your model with the current batch size\n",
    "        epoch_history = model.fit(\n",
    "            X, y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=(n+1)*epochs_per_batch,\n",
    "            initial_epoch=n*epochs_per_batch,  \n",
    "            validation_split=0.15,\n",
    "            verbose=1,\n",
    "            callbacks = [early_stopping]\n",
    "        )\n",
    "\n",
    "        # Append the results to the history dictionary\n",
    "        hist['loss'].extend(epoch_history.history['loss'])\n",
    "        hist['val_loss'].extend(epoch_history.history['val_loss'])\n",
    "        if acc:\n",
    "            hist['accuracy'].extend(epoch_history.history['accuracy'])\n",
    "            hist['val_accuracy'].extend(epoch_history.history['val_accuracy'])\n",
    "        if model.stop_training:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "        \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904c5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_endgame_data(endgame: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load position and pair data for an endgame from .npz files.\n",
    "\n",
    "    Args:\n",
    "        endgame (str): Name of the endgame (e.g., 'KRK').\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "            - positions: Position data (shape: (N, channels, 8, 8)).\n",
    "            - dtm_values: DTM values (shape: (N,)).\n",
    "            - positions1: First positions for pairs (shape: (M, channels, 8, 8)).\n",
    "            - positions2: Second positions for pairs (shape: (M, channels, 8, 8)).\n",
    "            - labels: Pair labels (shape: (M,), values in {0, 1, 2}).\n",
    "    \"\"\"\n",
    "    \n",
    "    data = np.load(fr\"DataBase\\{endgame}_position_train_val.npz\")\n",
    "    positions, dtm_values = data[\"positions\"], data[\"dtm_values\"]\n",
    "    print(f\"Loaded {endgame} position data with {dtm_values.shape[0]} samples\")\n",
    "\n",
    "    pair_data = np.load(fr\"DataBase\\{endgame}_pairs_train_val.npz\")\n",
    "    positions1, positions2, labels = pair_data[\"positions1\"], pair_data[\"positions2\"], pair_data[\"labels\"]\n",
    "    print(f\"Loaded {endgame} pair data with {labels.shape[0]} samples\")\n",
    "\n",
    "    return positions, dtm_values, positions1, positions2, labels\n",
    "\n",
    "def train_model(model, inputs, labels: np.ndarray, model_name: str, endgame: str, track_accuracy: bool, force_train: bool = False):\n",
    "    \"\"\"\n",
    "    Train a model and save its weights and history.\n",
    "\n",
    "    Args:\n",
    "        model: Keras model to train.\n",
    "        inputs: Input data (single array or tuple of two arrays for pairwise models).\n",
    "        labels: Target labels.\n",
    "        model_name: Name of the model (e.g., 'single', 'regression').\n",
    "        endgame: Name of the endgame (e.g., 'KRK').\n",
    "        track_accuracy: Whether to track accuracy (for classification models).\n",
    "\n",
    "    Returns:\n",
    "        Trained model and history.\n",
    "\n",
    "    \"\"\"    \n",
    "    model_path = fr\"Models\\{endgame}_model_{model_name}.keras\"\n",
    "    if not force_train and os.path.exists(model_path):\n",
    "        print(f\"Loading existing {model_name} model for {endgame} from {model_path}.\")\n",
    "        model = load_model(model_path)\n",
    "        return model\n",
    "    model, history = training(model, inputs, labels, acc=track_accuracy)\n",
    "\n",
    "    model.save(model_path)\n",
    "    history_path = fr\"Histories\\{endgame}_history_{model_name}.pkl\"\n",
    "    with open(history_path, \"wb\") as f:\n",
    "        pickle.dump(history, f)\n",
    "    print(f\"Saved model to {model_path} and history to {history_path}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def post_process_single(model, positions1: np.ndarray, positions2: np.ndarray, labels: np.ndarray, max_samples: int, endgame: str, model_name: str, post_nn_epochs: int, post_nn_batch_size: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Apply post-processing for single-input model (thresholding and neural network).\n",
    "\n",
    "    Args:\n",
    "        model: Trained single-input model.\n",
    "        positions1: First positions (shape: (M, channels, 8, 8)).\n",
    "        positions2: Second positions (shape: (M, channels, 8, 8)).\n",
    "        labels: True labels (shape: (M,), values in {0, 1, 2}).\n",
    "        max_samples: Maximum number of samples for post-processing.\n",
    "        model_dir: Directory to save the post-processing model.\n",
    "        endgame: Name of the endgame.\n",
    "        model_name: Name of the model.\n",
    "        post_nn_epochs: Epochs for post-processing neural network.\n",
    "        post_nn_batch_size: Batch size for post-processing neural network.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Threshold configuration (threshold1, threshold2).\n",
    "\n",
    "    \"\"\"\n",
    "    sample_indices = np.arange(min(max_samples, labels.shape[0]))\n",
    "    y1_pred = model.predict(positions1[sample_indices], batch_size=32)\n",
    "    y2_pred = model.predict(positions2[sample_indices], batch_size=32)\n",
    "    y_pred_comb = np.hstack([y1_pred, y2_pred])\n",
    "\n",
    "    # Threshold method\n",
    "    best_threshold, best_accuracy = find_best_threshold_v1(y1_pred, y2_pred, labels[sample_indices])\n",
    "    print(f\"Single model thresholds: threshold={best_threshold:.4f}, Accuracy={best_accuracy:.4f}\")\n",
    "    threshold_config = {\"threshold1\": float(best_threshold), \"threshold2\": 0.0}\n",
    "\n",
    "    # Post-processing neural network\n",
    "    post_model = create_post_nn(2)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "    post_model.fit(y_pred_comb, labels[sample_indices], epochs=post_nn_epochs,\n",
    "                  batch_size=post_nn_batch_size, validation_split=0.15, callbacks=[early_stopping])\n",
    "    post_model.save(fr\"Models\\{endgame}_model_pro_{model_name}.keras\")\n",
    "\n",
    "    return threshold_config\n",
    "\n",
    "def post_process_regression(model, positions1: np.ndarray, positions2: np.ndarray, labels: np.ndarray, max_samples: int, endgame: str, model_name: str, post_nn_epochs: int, post_nn_batch_size: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Apply post-processing for regression model (thresholding and neural network).\n",
    "\n",
    "    Args:\n",
    "        model: Trained regression model.\n",
    "        positions1: First positions (shape: (M, channels, 8, 8)).\n",
    "        positions2: Second positions (shape: (M, channels, 8, 8)).\n",
    "        labels: True labels (shape: (M,), values in {0, 1, 2}).\n",
    "        max_samples: Maximum number of samples for post-processing.\n",
    "        model_dir: Directory to save the post-processing model.\n",
    "        endgame: Name of the endgame.\n",
    "        model_name: Name of the model.\n",
    "        post_nn_epochs: Epochs for post-processing neural network.\n",
    "        post_nn_batch_size: Batch size for post-processing neural network.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Threshold configuration (threshold1, threshold2).\n",
    "    \"\"\"\n",
    "    sample_indices = np.arange(min(max_samples, labels.shape[0]))\n",
    "    y_pred = model.predict([positions1[sample_indices], positions2[sample_indices]], batch_size=32)\n",
    "\n",
    "    # Threshold method\n",
    "    best_t1, best_t2, best_acc = find_best_thresholds_v2(y_pred, labels[sample_indices])\n",
    "    print(f\"Regression model thresholds: t1={best_t1:.4f}, t2={best_t2:.4f}, Accuracy={best_acc:.4f}\")\n",
    "    threshold_config = {\"threshold1\": float(best_t1), \"threshold2\": float(best_t2)}\n",
    "\n",
    "    # Post-processing neural network\n",
    "    post_model = create_post_nn(1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "    post_model.fit(y_pred, labels[sample_indices], epochs=post_nn_epochs,\n",
    "                  batch_size=post_nn_batch_size, validation_split=0.15, callbacks=[early_stopping])\n",
    "    post_model.save(fr\"Models\\{endgame}_model_pro_{model_name}.keras\")\n",
    "\n",
    "    return threshold_config\n",
    "\n",
    "def save_threshold_config(threshold_config: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Save threshold configuration to JSON file, preserving existing entries.\n",
    "\n",
    "    Args:\n",
    "        threshold_config (Dict): Threshold configuration dictionary.\n",
    "        config_dir (str): Directory to save thresholds.json.\n",
    "\n",
    "    Raises:\n",
    "        OSError: If file saving fails.\n",
    "    \"\"\"\n",
    "    threshold_config_path = r\"Configs\\thresholds.json\"\n",
    "    existing_config = {}\n",
    "    if os.path.exists(threshold_config_path):\n",
    "        with open(threshold_config_path, \"r\") as f:\n",
    "            existing_config = json.load(f)\n",
    "        \n",
    "    existing_config.update(threshold_config)\n",
    "    with open(threshold_config_path, \"w\") as f:\n",
    "        json.dump(existing_config, f, indent=4)\n",
    "    print(f\"Updated threshold config saved to {threshold_config_path}\")\n",
    "    \n",
    "def train_endgame_models(endgames: List[str], model_types: List, max_samples: int = 100_000, post_nn_epochs: int = 5, post_nn_batch_size: int = 32, force_train: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Train models for multiple chess endgames, apply post-processing, and save results.\n",
    "\n",
    "    Args:\n",
    "        endgames (List[str]): List of endgame names (e.g., ['KRK', 'KPKR']).\n",
    "        model_types (List[Tuple[str, Callable]]): List of (model_name, create_function) pairs.\n",
    "        data_dir (str): Directory containing .npz data files (default: 'DataBase').\n",
    "        model_dir (str): Directory to save trained models (default: 'Models').\n",
    "        history_dir (str): Directory to save training histories (default: 'Histories').\n",
    "        config_dir (str): Directory to save threshold configurations (default: 'Configs').\n",
    "        max_samples (int): Maximum number of samples for post-processing (default: 100,000).\n",
    "        post_nn_epochs (int): Epochs for post-processing neural network (default: 10).\n",
    "        post_nn_batch_size (int): Batch size for post-processing neural network (default: 32).\n",
    "\n",
    "    Returns:\n",
    "        Dict: Threshold configurations for each endgame and model.\n",
    "    \"\"\"\n",
    "    threshold_config = {}\n",
    "\n",
    "    for endgame in endgames:\n",
    "        # Load data\n",
    "        positions, dtm_values, positions1, positions2, labels = load_endgame_data(endgame)\n",
    "\n",
    "        for model_name, create_func in model_types:\n",
    "\n",
    "            print(f\"\\nTraining {model_name} model for {endgame}\")\n",
    "            model = create_func(positions.shape[1])\n",
    "            # Transform labels for regression model\n",
    "            if model_name == \"regression\":\n",
    "                # Map: 0=equal, 1=pos1 better, 2=pos2 better to 0=equal, -1=pos1 better, 1=pos2 better\n",
    "                labels_trans = np.where(labels == 1, -1, np.where(labels == 2, 1, 0))\n",
    "            elif model_name == \"single\":\n",
    "                labels_trans = dtm_values\n",
    "            else:\n",
    "                labels_trans = labels\n",
    "\n",
    "            # Train model\n",
    "            inputs = positions if model_name == \"single\" else [positions1, positions2]\n",
    "            model = train_model(model, inputs, labels_trans, model_name, endgame,track_accuracy = model_name == \"classification\",force_train=force_train)\n",
    "\n",
    "            # Post-processing\n",
    "            if model_name == \"single\":\n",
    "                thresholds = post_process_single(model, positions1, positions2, labels, max_samples,\n",
    "                                               endgame, model_name, post_nn_epochs, post_nn_batch_size)\n",
    "            elif model_name == \"regression\":\n",
    "                thresholds = post_process_regression(model, positions1, positions2, labels, max_samples,\n",
    "                                                   endgame, model_name, post_nn_epochs, post_nn_batch_size)\n",
    "            else:\n",
    "                thresholds = {\"threshold1\": 0.0, \"threshold2\": 0.0}  # No thresholding for classification\n",
    "\n",
    "            threshold_config.setdefault(endgame, {})[model_name] = thresholds\n",
    "            save_threshold_config(threshold_config)\n",
    "\n",
    "            backend.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "    return threshold_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3820c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded KRK position data with 50500 samples\n",
      "Loaded KRK pair data with 450000 samples\n",
      "\n",
      "Training single model for KRK\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m1342/1342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 2/5\n",
      "\u001b[1m1342/1342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 3/5\n",
      "\u001b[1m1342/1342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 4/5\n",
      "\u001b[1m1342/1342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 5/5\n",
      "\u001b[1m1342/1342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 7/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 8.2578e-04 - mse: 8.2578e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 8/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 8.9306e-04 - mse: 8.9306e-04 - val_loss: 9.8798e-04 - val_mse: 9.8798e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 6.2278e-04 - mse: 6.2278e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 10/10\n",
      "\u001b[1m671/671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 6.9018e-04 - mse: 6.9018e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 5.7332e-04 - mse: 5.7332e-04 - val_loss: 6.3425e-04 - val_mse: 6.3425e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 4.0305e-04 - mse: 4.0305e-04 - val_loss: 5.8493e-04 - val_mse: 5.8493e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.4102e-04 - mse: 3.4102e-04 - val_loss: 5.6082e-04 - val_mse: 5.6082e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.1349e-04 - mse: 3.1349e-04 - val_loss: 6.6512e-04 - val_mse: 6.6512e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.1193e-04 - mse: 3.1193e-04 - val_loss: 4.8962e-04 - val_mse: 4.8962e-04\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.0077e-04 - mse: 2.0077e-04 - val_loss: 4.3728e-04 - val_mse: 4.3728e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.8091e-04 - mse: 1.8091e-04 - val_loss: 3.9563e-04 - val_mse: 3.9563e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.4782e-04 - mse: 1.4782e-04 - val_loss: 4.2523e-04 - val_mse: 4.2523e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.5169e-04 - mse: 1.5169e-04 - val_loss: 4.1993e-04 - val_mse: 4.1993e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.1615e-04 - mse: 1.1615e-04 - val_loss: 3.8173e-04 - val_mse: 3.8173e-04\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 9.5187e-05 - mse: 9.5187e-05 - val_loss: 3.4218e-04 - val_mse: 3.4218e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 6.8534e-05 - mse: 6.8534e-05 - val_loss: 3.4901e-04 - val_mse: 3.4901e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 7.0033e-05 - mse: 7.0033e-05 - val_loss: 3.4894e-04 - val_mse: 3.4894e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 6.7452e-05 - mse: 6.7452e-05 - val_loss: 3.3892e-04 - val_mse: 3.3892e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 6.0363e-05 - mse: 6.0363e-05 - val_loss: 3.3202e-04 - val_mse: 3.3202e-04\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Saved model to Models\\KRK_model_single.keras and history to Histories\\KRK_history_single.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "Single model thresholds: threshold=0.0005, Accuracy=0.9045\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6846 - loss: 0.8032 - val_accuracy: 0.9007 - val_loss: 0.3566\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 947us/step - accuracy: 0.9037 - loss: 0.3175 - val_accuracy: 0.9015 - val_loss: 0.2757\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 969us/step - accuracy: 0.9043 - loss: 0.2626 - val_accuracy: 0.9016 - val_loss: 0.2553\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 946us/step - accuracy: 0.9049 - loss: 0.2474 - val_accuracy: 0.9014 - val_loss: 0.2473\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 990us/step - accuracy: 0.9052 - loss: 0.2357 - val_accuracy: 0.9010 - val_loss: 0.2437\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "WARNING:tensorflow:From c:\\Users\\pocke\\miniconda3\\envs\\speed\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "Training regression model for KRK\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 6ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.1071 - val_mse: 0.1071\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0774 - val_mse: 0.0774\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 0.0735 - mse: 0.0735 - val_loss: 0.0669 - val_mse: 0.0669\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0572 - val_mse: 0.0572\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 8ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0433 - val_mse: 0.0433\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 8ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 8ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 8ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 8ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 12ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 41ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KRK_model_regression.keras and history to Histories\\KRK_history_regression.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "Regression model thresholds: t1=-0.5829, t2=0.4663, Accuracy=0.9952\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7498 - loss: 0.4734 - val_accuracy: 0.9933 - val_loss: 0.0387\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0284 - val_accuracy: 0.9945 - val_loss: 0.0218\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9951 - loss: 0.0202 - val_accuracy: 0.9946 - val_loss: 0.0210\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9949 - loss: 0.0201 - val_accuracy: 0.9947 - val_loss: 0.0209\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0187 - val_accuracy: 0.9945 - val_loss: 0.0209\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training classification model for KRK\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.8803 - loss: 0.3099 - val_accuracy: 0.9365 - val_loss: 0.1568\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.9410 - loss: 0.1469 - val_accuracy: 0.9455 - val_loss: 0.1307\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.1236 - val_accuracy: 0.9477 - val_loss: 0.1278\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.9535 - loss: 0.1104 - val_accuracy: 0.9520 - val_loss: 0.1143\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9569 - loss: 0.1010 - val_accuracy: 0.9567 - val_loss: 0.1029\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 9ms/step - accuracy: 0.9647 - loss: 0.0824 - val_accuracy: 0.9597 - val_loss: 0.0922\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.0779 - val_accuracy: 0.9620 - val_loss: 0.0886\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.0718 - val_accuracy: 0.9626 - val_loss: 0.0882\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 8ms/step - accuracy: 0.9710 - loss: 0.0685 - val_accuracy: 0.9644 - val_loss: 0.0841\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 9ms/step - accuracy: 0.9725 - loss: 0.0646 - val_accuracy: 0.9664 - val_loss: 0.0801\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.9783 - loss: 0.0514 - val_accuracy: 0.9677 - val_loss: 0.0788\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.9805 - loss: 0.0476 - val_accuracy: 0.9687 - val_loss: 0.0785\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9814 - loss: 0.0454 - val_accuracy: 0.9687 - val_loss: 0.0819\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9824 - loss: 0.0427 - val_accuracy: 0.9695 - val_loss: 0.0790\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0405 - val_accuracy: 0.9713 - val_loss: 0.0761\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 25ms/step - accuracy: 0.9885 - loss: 0.0291 - val_accuracy: 0.9725 - val_loss: 0.0805\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 24ms/step - accuracy: 0.9899 - loss: 0.0253 - val_accuracy: 0.9725 - val_loss: 0.0811\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 24ms/step - accuracy: 0.9904 - loss: 0.0246 - val_accuracy: 0.9712 - val_loss: 0.0878\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 24ms/step - accuracy: 0.9908 - loss: 0.0236 - val_accuracy: 0.9729 - val_loss: 0.0865\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 24ms/step - accuracy: 0.9913 - loss: 0.0221 - val_accuracy: 0.9722 - val_loss: 0.0934\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 45ms/step - accuracy: 0.9930 - loss: 0.0188 - val_accuracy: 0.9741 - val_loss: 0.0856\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9944 - loss: 0.0154 - val_accuracy: 0.9733 - val_loss: 0.0934\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9939 - loss: 0.0158 - val_accuracy: 0.9737 - val_loss: 0.0946\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9945 - loss: 0.0144 - val_accuracy: 0.9733 - val_loss: 0.0966\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9946 - loss: 0.0143 - val_accuracy: 0.9736 - val_loss: 0.1039\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KRK_model_classification.keras and history to Histories\\KRK_history_classification.pkl\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "Loaded KQKR position data with 900000 samples\n",
      "Loaded KQKR pair data with 450000 samples\n",
      "\n",
      "Training single model for KQKR\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 7ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 2/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 7ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 3/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 7ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 4/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 7ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 5/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 7ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 9ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 7/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 9ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 8/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 9ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 9/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 9ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 10/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 9ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 13ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 12/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 12ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 13/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 12ms/step - loss: 9.1665e-04 - mse: 9.1665e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 14/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 12ms/step - loss: 9.0880e-04 - mse: 9.0880e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 15/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 12ms/step - loss: 8.3447e-04 - mse: 8.3447e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 20ms/step - loss: 6.8182e-04 - mse: 6.8182e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 17/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 19ms/step - loss: 6.2243e-04 - mse: 6.2243e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 18/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 19ms/step - loss: 5.9840e-04 - mse: 5.9840e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 19/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 19ms/step - loss: 5.6576e-04 - mse: 5.6576e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 20/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 19ms/step - loss: 5.5211e-04 - mse: 5.5211e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 34ms/step - loss: 4.9791e-04 - mse: 4.9791e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 22/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 32ms/step - loss: 4.6150e-04 - mse: 4.6150e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 23/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.3620e-04 - mse: 4.3620e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 24/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 4.3045e-04 - mse: 4.3045e-04 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 25/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 33ms/step - loss: 4.0250e-04 - mse: 4.0250e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "Saved model to Models\\KQKR_model_single.keras and history to Histories\\KQKR_history_single.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "Single model thresholds: threshold=0.0020, Accuracy=0.8119\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7111 - loss: 0.8464 - val_accuracy: 0.8093 - val_loss: 0.5357\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8102 - loss: 0.5174 - val_accuracy: 0.8094 - val_loss: 0.4980\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8140 - loss: 0.4905 - val_accuracy: 0.8087 - val_loss: 0.4967\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8101 - loss: 0.4909 - val_accuracy: 0.8098 - val_loss: 0.4941\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8110 - loss: 0.4927 - val_accuracy: 0.8097 - val_loss: 0.4938\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training regression model for KQKR\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 8ms/step - loss: 0.5498 - mse: 0.5498 - val_loss: 0.3776 - val_mse: 0.3776\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 8ms/step - loss: 0.3592 - mse: 0.3592 - val_loss: 0.3052 - val_mse: 0.3052\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 8ms/step - loss: 0.2852 - mse: 0.2852 - val_loss: 0.2615 - val_mse: 0.2615\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 8ms/step - loss: 0.2439 - mse: 0.2439 - val_loss: 0.2301 - val_mse: 0.2301\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 8ms/step - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2168 - val_mse: 0.2168\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 10ms/step - loss: 0.1719 - mse: 0.1719 - val_loss: 0.1882 - val_mse: 0.1882\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 10ms/step - loss: 0.1574 - mse: 0.1574 - val_loss: 0.1884 - val_mse: 0.1884\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 10ms/step - loss: 0.1450 - mse: 0.1450 - val_loss: 0.1766 - val_mse: 0.1766\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 10ms/step - loss: 0.1358 - mse: 0.1358 - val_loss: 0.1706 - val_mse: 0.1706\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 10ms/step - loss: 0.1275 - mse: 0.1275 - val_loss: 0.1736 - val_mse: 0.1736\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 17ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 0.1645 - val_mse: 0.1645\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 0.1640 - val_mse: 0.1640\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - loss: 0.0970 - mse: 0.0970 - val_loss: 0.1616 - val_mse: 0.1616\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 16ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 0.1668 - val_mse: 0.1668\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 17ms/step - loss: 0.0881 - mse: 0.0881 - val_loss: 0.1629 - val_mse: 0.1629\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 33ms/step - loss: 0.0790 - mse: 0.0790 - val_loss: 0.1604 - val_mse: 0.1604\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 32ms/step - loss: 0.0725 - mse: 0.0725 - val_loss: 0.1616 - val_mse: 0.1616\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.1622 - val_mse: 0.1622\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 32ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.1653 - val_mse: 0.1653\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 32ms/step - loss: 0.0647 - mse: 0.0647 - val_loss: 0.1640 - val_mse: 0.1640\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 61ms/step - loss: 0.0631 - mse: 0.0631 - val_loss: 0.1609 - val_mse: 0.1609\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 60ms/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.1630 - val_mse: 0.1630\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 60ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.1658 - val_mse: 0.1658\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 61ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.1672 - val_mse: 0.1672\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 60ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.1683 - val_mse: 0.1683\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KQKR_model_regression.keras and history to Histories\\KQKR_history_regression.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step\n",
      "Regression model thresholds: t1=-0.1688, t2=0.3216, Accuracy=0.9614\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8357 - loss: 0.4833 - val_accuracy: 0.9609 - val_loss: 0.1621\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.1586 - val_accuracy: 0.9607 - val_loss: 0.1479\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9600 - loss: 0.1528 - val_accuracy: 0.9599 - val_loss: 0.1463\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.1528 - val_accuracy: 0.9596 - val_loss: 0.1466\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9597 - loss: 0.1532 - val_accuracy: 0.9604 - val_loss: 0.1464\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training classification model for KQKR\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 9ms/step - accuracy: 0.7255 - loss: 0.6620 - val_accuracy: 0.8357 - val_loss: 0.4255\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 9ms/step - accuracy: 0.8450 - loss: 0.4020 - val_accuracy: 0.8713 - val_loss: 0.3344\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 9ms/step - accuracy: 0.8781 - loss: 0.3193 - val_accuracy: 0.8849 - val_loss: 0.3000\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 9ms/step - accuracy: 0.8950 - loss: 0.2742 - val_accuracy: 0.9012 - val_loss: 0.2585\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 9ms/step - accuracy: 0.9066 - loss: 0.2448 - val_accuracy: 0.9043 - val_loss: 0.2520\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 12ms/step - accuracy: 0.9244 - loss: 0.1995 - val_accuracy: 0.9139 - val_loss: 0.2293\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 11ms/step - accuracy: 0.9298 - loss: 0.1861 - val_accuracy: 0.9179 - val_loss: 0.2161\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 11ms/step - accuracy: 0.9329 - loss: 0.1754 - val_accuracy: 0.9216 - val_loss: 0.2083\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 12ms/step - accuracy: 0.9363 - loss: 0.1670 - val_accuracy: 0.9195 - val_loss: 0.2152\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 12ms/step - accuracy: 0.9386 - loss: 0.1608 - val_accuracy: 0.9221 - val_loss: 0.2082\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 20ms/step - accuracy: 0.9484 - loss: 0.1349 - val_accuracy: 0.9266 - val_loss: 0.2052\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 20ms/step - accuracy: 0.9519 - loss: 0.1270 - val_accuracy: 0.9265 - val_loss: 0.2002\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 20ms/step - accuracy: 0.9539 - loss: 0.1215 - val_accuracy: 0.9271 - val_loss: 0.2070\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 20ms/step - accuracy: 0.9560 - loss: 0.1158 - val_accuracy: 0.9279 - val_loss: 0.2064\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 20ms/step - accuracy: 0.9575 - loss: 0.1113 - val_accuracy: 0.9267 - val_loss: 0.2134\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 40ms/step - accuracy: 0.9593 - loss: 0.1068 - val_accuracy: 0.9275 - val_loss: 0.2075\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 38ms/step - accuracy: 0.9621 - loss: 0.1007 - val_accuracy: 0.9286 - val_loss: 0.2121\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 38ms/step - accuracy: 0.9633 - loss: 0.0963 - val_accuracy: 0.9244 - val_loss: 0.2228\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - accuracy: 0.9658 - loss: 0.0910 - val_accuracy: 0.9273 - val_loss: 0.2213\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 39ms/step - accuracy: 0.9670 - loss: 0.0859 - val_accuracy: 0.9266 - val_loss: 0.2339\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 69ms/step - accuracy: 0.9662 - loss: 0.0899 - val_accuracy: 0.9298 - val_loss: 0.2177\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 67ms/step - accuracy: 0.9691 - loss: 0.0825 - val_accuracy: 0.9279 - val_loss: 0.2295\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 67ms/step - accuracy: 0.9702 - loss: 0.0794 - val_accuracy: 0.9276 - val_loss: 0.2396\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9710 - loss: 0.0776 - val_accuracy: 0.9257 - val_loss: 0.2493\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9720 - loss: 0.0745 - val_accuracy: 0.9270 - val_loss: 0.2521\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KQKR_model_classification.keras and history to Histories\\KQKR_history_classification.pkl\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "Loaded KRKP position data with 900000 samples\n",
      "Loaded KRKP pair data with 450000 samples\n",
      "\n",
      "Training single model for KRKP\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 7ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 2/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 7ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 3/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 7ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 4/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 7ms/step - loss: 8.5982e-04 - mse: 8.5982e-04 - val_loss: 8.8362e-04 - val_mse: 8.8362e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 7ms/step - loss: 8.0584e-04 - mse: 8.0584e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 10ms/step - loss: 6.7993e-04 - mse: 6.7993e-04 - val_loss: 7.1465e-04 - val_mse: 7.1465e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 10ms/step - loss: 6.2461e-04 - mse: 6.2461e-04 - val_loss: 7.3919e-04 - val_mse: 7.3919e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 10ms/step - loss: 5.5715e-04 - mse: 5.5715e-04 - val_loss: 7.0824e-04 - val_mse: 7.0824e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 10ms/step - loss: 5.2013e-04 - mse: 5.2013e-04 - val_loss: 7.3260e-04 - val_mse: 7.3260e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 10ms/step - loss: 4.8507e-04 - mse: 4.8507e-04 - val_loss: 7.4857e-04 - val_mse: 7.4857e-04\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 15ms/step - loss: 4.5658e-04 - mse: 4.5658e-04 - val_loss: 6.1516e-04 - val_mse: 6.1516e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 15ms/step - loss: 4.2250e-04 - mse: 4.2250e-04 - val_loss: 5.6236e-04 - val_mse: 5.6236e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 15ms/step - loss: 3.7175e-04 - mse: 3.7175e-04 - val_loss: 6.0049e-04 - val_mse: 6.0049e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 14ms/step - loss: 3.6269e-04 - mse: 3.6269e-04 - val_loss: 5.4856e-04 - val_mse: 5.4856e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 14ms/step - loss: 3.2945e-04 - mse: 3.2945e-04 - val_loss: 5.4827e-04 - val_mse: 5.4827e-04\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 24ms/step - loss: 2.7805e-04 - mse: 2.7805e-04 - val_loss: 5.1707e-04 - val_mse: 5.1707e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 23ms/step - loss: 2.6674e-04 - mse: 2.6674e-04 - val_loss: 4.6908e-04 - val_mse: 4.6908e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 23ms/step - loss: 2.3474e-04 - mse: 2.3474e-04 - val_loss: 5.1092e-04 - val_mse: 5.1092e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 23ms/step - loss: 2.3757e-04 - mse: 2.3757e-04 - val_loss: 4.9595e-04 - val_mse: 4.9595e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 23ms/step - loss: 2.0102e-04 - mse: 2.0102e-04 - val_loss: 4.9669e-04 - val_mse: 4.9669e-04\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - loss: 2.1595e-04 - mse: 2.1595e-04 - val_loss: 4.8772e-04 - val_mse: 4.8772e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 38ms/step - loss: 2.0217e-04 - mse: 2.0217e-04 - val_loss: 4.8493e-04 - val_mse: 4.8493e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 40ms/step - loss: 1.9455e-04 - mse: 1.9455e-04 - val_loss: 4.7611e-04 - val_mse: 4.7611e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 40ms/step - loss: 1.7487e-04 - mse: 1.7487e-04 - val_loss: 4.5776e-04 - val_mse: 4.5776e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 40ms/step - loss: 1.7015e-04 - mse: 1.7015e-04 - val_loss: 4.7043e-04 - val_mse: 4.7043e-04\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Saved model to Models\\KRKP_model_single.keras and history to Histories\\KRKP_history_single.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "Single model thresholds: threshold=0.0000, Accuracy=0.8595\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.7085 - loss: 0.8387 - val_accuracy: 0.8537 - val_loss: 0.4854\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8615 - loss: 0.4433 - val_accuracy: 0.8558 - val_loss: 0.3957\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.3880 - val_accuracy: 0.8553 - val_loss: 0.3793\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8617 - loss: 0.3747 - val_accuracy: 0.8557 - val_loss: 0.3738\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8596 - loss: 0.3804 - val_accuracy: 0.8555 - val_loss: 0.3724\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training regression model for KRKP\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 10ms/step - loss: 0.4508 - mse: 0.4508 - val_loss: 0.2953 - val_mse: 0.2953\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 9ms/step - loss: 0.2815 - mse: 0.2815 - val_loss: 0.2544 - val_mse: 0.2544\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 9ms/step - loss: 0.2353 - mse: 0.2353 - val_loss: 0.2274 - val_mse: 0.2274\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 9ms/step - loss: 0.2089 - mse: 0.2089 - val_loss: 0.2101 - val_mse: 0.2101\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 9ms/step - loss: 0.1917 - mse: 0.1917 - val_loss: 0.2009 - val_mse: 0.2009\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 13ms/step - loss: 0.1591 - mse: 0.1591 - val_loss: 0.1848 - val_mse: 0.1848\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 12ms/step - loss: 0.1479 - mse: 0.1479 - val_loss: 0.1783 - val_mse: 0.1783\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 12ms/step - loss: 0.1398 - mse: 0.1398 - val_loss: 0.1761 - val_mse: 0.1761\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 12ms/step - loss: 0.1300 - mse: 0.1300 - val_loss: 0.1760 - val_mse: 0.1760\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 12ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 0.1754 - val_mse: 0.1754\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 21ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 0.1655 - val_mse: 0.1655\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 20ms/step - loss: 0.0970 - mse: 0.0970 - val_loss: 0.1677 - val_mse: 0.1677\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 20ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 0.1671 - val_mse: 0.1671\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 20ms/step - loss: 0.0881 - mse: 0.0881 - val_loss: 0.1716 - val_mse: 0.1716\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 20ms/step - loss: 0.0833 - mse: 0.0833 - val_loss: 0.1690 - val_mse: 0.1690\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 40ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 0.1665 - val_mse: 0.1665\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - loss: 0.0802 - mse: 0.0802 - val_loss: 0.1677 - val_mse: 0.1677\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - loss: 0.0767 - mse: 0.0767 - val_loss: 0.1699 - val_mse: 0.1699\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.1707 - val_mse: 0.1707\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 39ms/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.1712 - val_mse: 0.1712\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 71ms/step - loss: 0.0745 - mse: 0.0745 - val_loss: 0.1653 - val_mse: 0.1653\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 69ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.1686 - val_mse: 0.1686\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 67ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.1688 - val_mse: 0.1688\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 67ms/step - loss: 0.0637 - mse: 0.0637 - val_loss: 0.1735 - val_mse: 0.1735\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 67ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.1733 - val_mse: 0.1733\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KRKP_model_regression.keras and history to Histories\\KRKP_history_regression.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step\n",
      "Regression model thresholds: t1=-0.3176, t2=0.3618, Accuracy=0.9469\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9041 - loss: 0.4094 - val_accuracy: 0.9471 - val_loss: 0.1948\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.1880 - val_accuracy: 0.9462 - val_loss: 0.1848\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 996us/step - accuracy: 0.9443 - loss: 0.1891 - val_accuracy: 0.9465 - val_loss: 0.1839\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1793 - val_accuracy: 0.9466 - val_loss: 0.1831\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1796 - val_accuracy: 0.9466 - val_loss: 0.1833\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training classification model for KRKP\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 10ms/step - accuracy: 0.7800 - loss: 0.5541 - val_accuracy: 0.8568 - val_loss: 0.3747\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 9ms/step - accuracy: 0.8612 - loss: 0.3653 - val_accuracy: 0.8794 - val_loss: 0.3211\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 10ms/step - accuracy: 0.8833 - loss: 0.3117 - val_accuracy: 0.8914 - val_loss: 0.2901\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 10ms/step - accuracy: 0.8959 - loss: 0.2787 - val_accuracy: 0.8940 - val_loss: 0.2832\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 10ms/step - accuracy: 0.9047 - loss: 0.2544 - val_accuracy: 0.9016 - val_loss: 0.2621\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 15ms/step - accuracy: 0.9193 - loss: 0.2140 - val_accuracy: 0.9085 - val_loss: 0.2461\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 14ms/step - accuracy: 0.9225 - loss: 0.2023 - val_accuracy: 0.9114 - val_loss: 0.2455\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 15ms/step - accuracy: 0.9277 - loss: 0.1897 - val_accuracy: 0.9140 - val_loss: 0.2365\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 15ms/step - accuracy: 0.9312 - loss: 0.1802 - val_accuracy: 0.9154 - val_loss: 0.2306\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 15ms/step - accuracy: 0.9334 - loss: 0.1736 - val_accuracy: 0.9151 - val_loss: 0.2260\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 26ms/step - accuracy: 0.9426 - loss: 0.1478 - val_accuracy: 0.9182 - val_loss: 0.2289\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 25ms/step - accuracy: 0.9454 - loss: 0.1392 - val_accuracy: 0.9190 - val_loss: 0.2368\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 25ms/step - accuracy: 0.9465 - loss: 0.1356 - val_accuracy: 0.9180 - val_loss: 0.2369\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 25ms/step - accuracy: 0.9498 - loss: 0.1269 - val_accuracy: 0.9187 - val_loss: 0.2409\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 26ms/step - accuracy: 0.9516 - loss: 0.1212 - val_accuracy: 0.9176 - val_loss: 0.2435\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 53ms/step - accuracy: 0.9506 - loss: 0.1254 - val_accuracy: 0.9187 - val_loss: 0.2379\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 50ms/step - accuracy: 0.9529 - loss: 0.1179 - val_accuracy: 0.9188 - val_loss: 0.2457\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 44ms/step - accuracy: 0.9552 - loss: 0.1125 - val_accuracy: 0.9182 - val_loss: 0.2467\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 44ms/step - accuracy: 0.9571 - loss: 0.1071 - val_accuracy: 0.9177 - val_loss: 0.2552\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 45ms/step - accuracy: 0.9588 - loss: 0.1022 - val_accuracy: 0.9159 - val_loss: 0.2670\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 77ms/step - accuracy: 0.9564 - loss: 0.1080 - val_accuracy: 0.9196 - val_loss: 0.2506\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 77ms/step - accuracy: 0.9605 - loss: 0.0991 - val_accuracy: 0.9173 - val_loss: 0.2619\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 73ms/step - accuracy: 0.9616 - loss: 0.0953 - val_accuracy: 0.9184 - val_loss: 0.2680\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 80ms/step - accuracy: 0.9635 - loss: 0.0912 - val_accuracy: 0.9165 - val_loss: 0.2843\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 88ms/step - accuracy: 0.9646 - loss: 0.0886 - val_accuracy: 0.9163 - val_loss: 0.2955\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KRKP_model_classification.keras and history to Histories\\KRKP_history_classification.pkl\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "Loaded KPK position data with 151221 samples\n",
      "Loaded KPK pair data with 450000 samples\n",
      "\n",
      "Training single model for KPK\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 4.3419e-04 - val_mse: 4.3419e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9ms/step - loss: 6.1237e-04 - mse: 6.1237e-04 - val_loss: 3.6591e-04 - val_mse: 3.6591e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9ms/step - loss: 5.1514e-04 - mse: 5.1514e-04 - val_loss: 3.7005e-04 - val_mse: 3.7005e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9ms/step - loss: 4.1544e-04 - mse: 4.1544e-04 - val_loss: 2.5713e-04 - val_mse: 2.5713e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m4017/4017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9ms/step - loss: 2.9683e-04 - mse: 2.9683e-04 - val_loss: 1.9729e-04 - val_mse: 1.9729e-04\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m2009/2009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - loss: 1.5721e-04 - mse: 1.5721e-04 - val_loss: 1.7442e-04 - val_mse: 1.7442e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m2009/2009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 1.6189e-04 - mse: 1.6189e-04 - val_loss: 2.0025e-04 - val_mse: 2.0025e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m2009/2009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 1.2774e-04 - mse: 1.2774e-04 - val_loss: 1.9421e-04 - val_mse: 1.9421e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m2009/2009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 1.3403e-04 - mse: 1.3403e-04 - val_loss: 1.9497e-04 - val_mse: 1.9497e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m2009/2009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - loss: 9.7448e-05 - mse: 9.7448e-05 - val_loss: 1.9884e-04 - val_mse: 1.9884e-04\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - loss: 1.1947e-04 - mse: 1.1947e-04 - val_loss: 1.7400e-04 - val_mse: 1.7400e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - loss: 1.3184e-04 - mse: 1.3184e-04 - val_loss: 1.2396e-04 - val_mse: 1.2396e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - loss: 9.0164e-05 - mse: 9.0164e-05 - val_loss: 1.7089e-04 - val_mse: 1.7089e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - loss: 1.2187e-04 - mse: 1.2187e-04 - val_loss: 1.2172e-04 - val_mse: 1.2172e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - loss: 9.4196e-05 - mse: 9.4196e-05 - val_loss: 1.9766e-04 - val_mse: 1.9766e-04\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - loss: 6.7305e-05 - mse: 6.7305e-05 - val_loss: 1.3571e-04 - val_mse: 1.3571e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - loss: 5.0325e-05 - mse: 5.0325e-05 - val_loss: 1.0756e-04 - val_mse: 1.0756e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - loss: 4.0646e-05 - mse: 4.0646e-05 - val_loss: 9.1172e-05 - val_mse: 9.1172e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - loss: 3.6388e-05 - mse: 3.6388e-05 - val_loss: 8.8351e-05 - val_mse: 8.8351e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - loss: 3.6661e-05 - mse: 3.6661e-05 - val_loss: 9.6306e-05 - val_mse: 9.6306e-05\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 3.3905e-05 - mse: 3.3905e-05 - val_loss: 8.7019e-05 - val_mse: 8.7019e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 2.9043e-05 - mse: 2.9043e-05 - val_loss: 9.8262e-05 - val_mse: 9.8262e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 2.7811e-05 - mse: 2.7811e-05 - val_loss: 9.5233e-05 - val_mse: 9.5233e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 2.5485e-05 - mse: 2.5485e-05 - val_loss: 1.0247e-04 - val_mse: 1.0247e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 3.2591e-05 - mse: 3.2591e-05 - val_loss: 1.0245e-04 - val_mse: 1.0245e-04\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KPK_model_single.keras and history to Histories\\KPK_history_single.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "Single model thresholds: threshold=0.0043, Accuracy=0.9444\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.8484 - val_accuracy: 0.8531 - val_loss: 0.3775\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8745 - loss: 0.3331 - val_accuracy: 0.9335 - val_loss: 0.2562\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9365 - loss: 0.2396 - val_accuracy: 0.9279 - val_loss: 0.2219\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9333 - loss: 0.2098 - val_accuracy: 0.9268 - val_loss: 0.2096\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9329 - loss: 0.1970 - val_accuracy: 0.9265 - val_loss: 0.2030\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training regression model for KPK\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 14ms/step - loss: 0.1831 - mse: 0.1831 - val_loss: 0.0696 - val_mse: 0.0696\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 13ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0549 - val_mse: 0.0549\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 13ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0528 - val_mse: 0.0528\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 10ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 10ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 16ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 16ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 17ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 17ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 17ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 25ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 25ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 25ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 25ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 25ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 41ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 41ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 41ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 41ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 41ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 70ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 69ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 69ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 69ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 69ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KPK_model_regression.keras and history to Histories\\KPK_history_regression.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step\n",
      "Regression model thresholds: t1=-0.4985, t2=0.4302, Accuracy=0.9948\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9177 - loss: 0.2983 - val_accuracy: 0.9936 - val_loss: 0.0299\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9949 - loss: 0.0241 - val_accuracy: 0.9938 - val_loss: 0.0262\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9948 - loss: 0.0209 - val_accuracy: 0.9938 - val_loss: 0.0262\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0230 - val_accuracy: 0.9938 - val_loss: 0.0257\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9949 - loss: 0.0217 - val_accuracy: 0.9937 - val_loss: 0.0258\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training classification model for KPK\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 12ms/step - accuracy: 0.8809 - loss: 0.2924 - val_accuracy: 0.9487 - val_loss: 0.1284\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 12ms/step - accuracy: 0.9508 - loss: 0.1220 - val_accuracy: 0.9504 - val_loss: 0.1243\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 12ms/step - accuracy: 0.9611 - loss: 0.0963 - val_accuracy: 0.9681 - val_loss: 0.0782\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 12ms/step - accuracy: 0.9672 - loss: 0.0812 - val_accuracy: 0.9692 - val_loss: 0.0762\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 11ms/step - accuracy: 0.9707 - loss: 0.0721 - val_accuracy: 0.9717 - val_loss: 0.0716\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 17ms/step - accuracy: 0.9788 - loss: 0.0528 - val_accuracy: 0.9750 - val_loss: 0.0615\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 17ms/step - accuracy: 0.9803 - loss: 0.0487 - val_accuracy: 0.9767 - val_loss: 0.0581\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 19ms/step - accuracy: 0.9820 - loss: 0.0447 - val_accuracy: 0.9749 - val_loss: 0.0630\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 19ms/step - accuracy: 0.9832 - loss: 0.0418 - val_accuracy: 0.9770 - val_loss: 0.0582\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 20ms/step - accuracy: 0.9845 - loss: 0.0389 - val_accuracy: 0.9782 - val_loss: 0.0562\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 29ms/step - accuracy: 0.9889 - loss: 0.0275 - val_accuracy: 0.9784 - val_loss: 0.0572\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 36ms/step - accuracy: 0.9896 - loss: 0.0263 - val_accuracy: 0.9799 - val_loss: 0.0584\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 45ms/step - accuracy: 0.9901 - loss: 0.0252 - val_accuracy: 0.9797 - val_loss: 0.0570\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 47ms/step - accuracy: 0.9907 - loss: 0.0229 - val_accuracy: 0.9796 - val_loss: 0.0593\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 47ms/step - accuracy: 0.9916 - loss: 0.0216 - val_accuracy: 0.9802 - val_loss: 0.0602\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 77ms/step - accuracy: 0.9940 - loss: 0.0160 - val_accuracy: 0.9808 - val_loss: 0.0649\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 75ms/step - accuracy: 0.9942 - loss: 0.0151 - val_accuracy: 0.9816 - val_loss: 0.0640\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 76ms/step - accuracy: 0.9948 - loss: 0.0137 - val_accuracy: 0.9806 - val_loss: 0.0677\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 67ms/step - accuracy: 0.9951 - loss: 0.0128 - val_accuracy: 0.9778 - val_loss: 0.0851\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 44ms/step - accuracy: 0.9955 - loss: 0.0123 - val_accuracy: 0.9805 - val_loss: 0.0748\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 73ms/step - accuracy: 0.9967 - loss: 0.0094 - val_accuracy: 0.9824 - val_loss: 0.0731\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 71ms/step - accuracy: 0.9977 - loss: 0.0065 - val_accuracy: 0.9822 - val_loss: 0.0749\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 70ms/step - accuracy: 0.9975 - loss: 0.0066 - val_accuracy: 0.9811 - val_loss: 0.0827\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 71ms/step - accuracy: 0.9957 - loss: 0.0132 - val_accuracy: 0.9820 - val_loss: 0.0811\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 71ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.9808 - val_loss: 0.0896\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KPK_model_classification.keras and history to Histories\\KPK_history_classification.pkl\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "Loaded KPKP position data with 900000 samples\n",
      "Loaded KPKP pair data with 450000 samples\n",
      "\n",
      "Training single model for KPKP\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 5.4077e-04 - val_mse: 5.4077e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 9ms/step - loss: 5.3405e-04 - mse: 5.3405e-04 - val_loss: 4.0457e-04 - val_mse: 4.0457e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 9ms/step - loss: 4.2525e-04 - mse: 4.2525e-04 - val_loss: 3.1694e-04 - val_mse: 3.1694e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 10ms/step - loss: 3.4361e-04 - mse: 3.4361e-04 - val_loss: 3.3280e-04 - val_mse: 3.3280e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 14ms/step - loss: 3.0150e-04 - mse: 3.0150e-04 - val_loss: 3.0652e-04 - val_mse: 3.0652e-04\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 22ms/step - loss: 2.3633e-04 - mse: 2.3633e-04 - val_loss: 2.5831e-04 - val_mse: 2.5831e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 21ms/step - loss: 2.2171e-04 - mse: 2.2171e-04 - val_loss: 2.2851e-04 - val_mse: 2.2851e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 21ms/step - loss: 1.9603e-04 - mse: 1.9603e-04 - val_loss: 2.0953e-04 - val_mse: 2.0953e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 22ms/step - loss: 1.8006e-04 - mse: 1.8006e-04 - val_loss: 2.0428e-04 - val_mse: 2.0428e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 22ms/step - loss: 1.7716e-04 - mse: 1.7716e-04 - val_loss: 2.0102e-04 - val_mse: 2.0102e-04\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 37ms/step - loss: 1.4251e-04 - mse: 1.4251e-04 - val_loss: 1.7875e-04 - val_mse: 1.7875e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 35ms/step - loss: 1.3111e-04 - mse: 1.3111e-04 - val_loss: 1.8138e-04 - val_mse: 1.8138e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 35ms/step - loss: 1.3283e-04 - mse: 1.3283e-04 - val_loss: 2.0461e-04 - val_mse: 2.0461e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 34ms/step - loss: 1.2474e-04 - mse: 1.2474e-04 - val_loss: 1.7188e-04 - val_mse: 1.7188e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 34ms/step - loss: 1.2064e-04 - mse: 1.2064e-04 - val_loss: 1.7775e-04 - val_mse: 1.7775e-04\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 63ms/step - loss: 1.0566e-04 - mse: 1.0566e-04 - val_loss: 1.6612e-04 - val_mse: 1.6612e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 63ms/step - loss: 1.0327e-04 - mse: 1.0327e-04 - val_loss: 1.7103e-04 - val_mse: 1.7103e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 58ms/step - loss: 1.0005e-04 - mse: 1.0005e-04 - val_loss: 1.6219e-04 - val_mse: 1.6219e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 61ms/step - loss: 9.6763e-05 - mse: 9.6763e-05 - val_loss: 1.7022e-04 - val_mse: 1.7022e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 63ms/step - loss: 9.2280e-05 - mse: 9.2280e-05 - val_loss: 1.7308e-04 - val_mse: 1.7308e-04\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 88ms/step - loss: 8.6489e-05 - mse: 8.6489e-05 - val_loss: 1.5536e-04 - val_mse: 1.5536e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 88ms/step - loss: 8.2415e-05 - mse: 8.2415e-05 - val_loss: 1.6132e-04 - val_mse: 1.6132e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 88ms/step - loss: 8.1070e-05 - mse: 8.1070e-05 - val_loss: 1.7275e-04 - val_mse: 1.7275e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 89ms/step - loss: 8.0210e-05 - mse: 8.0210e-05 - val_loss: 1.5882e-04 - val_mse: 1.5882e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 89ms/step - loss: 7.6206e-05 - mse: 7.6206e-05 - val_loss: 1.5745e-04 - val_mse: 1.5745e-04\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KPKP_model_single.keras and history to Histories\\KPKP_history_single.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step\n",
      "Single model thresholds: threshold=0.0063, Accuracy=0.8727\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8691 - val_accuracy: 0.8124 - val_loss: 0.4438\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.4084 - val_accuracy: 0.8830 - val_loss: 0.3447\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.3394 - val_accuracy: 0.8850 - val_loss: 0.3224\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.3258 - val_accuracy: 0.8845 - val_loss: 0.3193\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.3183 - val_accuracy: 0.8853 - val_loss: 0.3152\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training regression model for KPKP\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 22ms/step - loss: 0.3824 - mse: 0.3824 - val_loss: 0.2403 - val_mse: 0.2403\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 22ms/step - loss: 0.2211 - mse: 0.2211 - val_loss: 0.1920 - val_mse: 0.1920\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 22ms/step - loss: 0.1834 - mse: 0.1834 - val_loss: 0.1731 - val_mse: 0.1731\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 22ms/step - loss: 0.1632 - mse: 0.1632 - val_loss: 0.1572 - val_mse: 0.1572\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 22ms/step - loss: 0.1490 - mse: 0.1490 - val_loss: 0.1497 - val_mse: 0.1497\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 36ms/step - loss: 0.1226 - mse: 0.1226 - val_loss: 0.1414 - val_mse: 0.1414\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 35ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 0.1400 - val_mse: 0.1400\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 36ms/step - loss: 0.1078 - mse: 0.1078 - val_loss: 0.1413 - val_mse: 0.1413\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 36ms/step - loss: 0.1020 - mse: 0.1020 - val_loss: 0.1352 - val_mse: 0.1352\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 36ms/step - loss: 0.0986 - mse: 0.0986 - val_loss: 0.1316 - val_mse: 0.1316\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 62ms/step - loss: 0.0811 - mse: 0.0811 - val_loss: 0.1278 - val_mse: 0.1278\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 61ms/step - loss: 0.0762 - mse: 0.0762 - val_loss: 0.1226 - val_mse: 0.1226\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 62ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.1255 - val_mse: 0.1255\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 62ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.1265 - val_mse: 0.1265\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 62ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.1250 - val_mse: 0.1250\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 120ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.1229 - val_mse: 0.1229\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 117ms/step - loss: 0.0597 - mse: 0.0597 - val_loss: 0.1216 - val_mse: 0.1216\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 119ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.1254 - val_mse: 0.1254\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 124ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.1261 - val_mse: 0.1261\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 123ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.1250 - val_mse: 0.1250\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 175ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.1216 - val_mse: 0.1216\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 173ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.1221 - val_mse: 0.1221\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m849s\u001b[0m 1s/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.1240 - val_mse: 0.1240\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33512s\u001b[0m 45s/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.1259 - val_mse: 0.1259\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3975s\u001b[0m 5s/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.1286 - val_mse: 0.1286\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KPKP_model_regression.keras and history to Histories\\KPKP_history_regression.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step\n",
      "Regression model thresholds: t1=-0.4864, t2=0.4985, Accuracy=0.9473\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8300 - loss: 0.4902 - val_accuracy: 0.9463 - val_loss: 0.1809\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1713 - val_accuracy: 0.9459 - val_loss: 0.1756\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1708 - val_accuracy: 0.9461 - val_loss: 0.1742\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1673 - val_accuracy: 0.9464 - val_loss: 0.1731\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1676 - val_accuracy: 0.9459 - val_loss: 0.1718\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training classification model for KPKP\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 14ms/step - accuracy: 0.7437 - loss: 0.6137 - val_accuracy: 0.8367 - val_loss: 0.4026\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 14ms/step - accuracy: 0.8449 - loss: 0.3855 - val_accuracy: 0.8615 - val_loss: 0.3411\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 14ms/step - accuracy: 0.8653 - loss: 0.3326 - val_accuracy: 0.8700 - val_loss: 0.3241\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 14ms/step - accuracy: 0.8778 - loss: 0.3017 - val_accuracy: 0.8785 - val_loss: 0.3003\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 14ms/step - accuracy: 0.8872 - loss: 0.2776 - val_accuracy: 0.8833 - val_loss: 0.2893\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 22ms/step - accuracy: 0.9049 - loss: 0.2340 - val_accuracy: 0.8949 - val_loss: 0.2620\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 22ms/step - accuracy: 0.9101 - loss: 0.2198 - val_accuracy: 0.8937 - val_loss: 0.2631\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 22ms/step - accuracy: 0.9148 - loss: 0.2086 - val_accuracy: 0.8968 - val_loss: 0.2577\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 22ms/step - accuracy: 0.9184 - loss: 0.1996 - val_accuracy: 0.8943 - val_loss: 0.2634\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 23ms/step - accuracy: 0.9230 - loss: 0.1900 - val_accuracy: 0.8990 - val_loss: 0.2531\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 40ms/step - accuracy: 0.9354 - loss: 0.1584 - val_accuracy: 0.8994 - val_loss: 0.2627\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 39ms/step - accuracy: 0.9381 - loss: 0.1516 - val_accuracy: 0.9021 - val_loss: 0.2590\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 39ms/step - accuracy: 0.9413 - loss: 0.1438 - val_accuracy: 0.9041 - val_loss: 0.2575\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 39ms/step - accuracy: 0.9442 - loss: 0.1362 - val_accuracy: 0.9043 - val_loss: 0.2644\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 39ms/step - accuracy: 0.9475 - loss: 0.1295 - val_accuracy: 0.9018 - val_loss: 0.2751\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 76ms/step - accuracy: 0.9535 - loss: 0.1159 - val_accuracy: 0.9049 - val_loss: 0.2739\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 75ms/step - accuracy: 0.9563 - loss: 0.1092 - val_accuracy: 0.9039 - val_loss: 0.2835\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 76ms/step - accuracy: 0.9583 - loss: 0.1043 - val_accuracy: 0.9039 - val_loss: 0.2971\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 75ms/step - accuracy: 0.9602 - loss: 0.0994 - val_accuracy: 0.9029 - val_loss: 0.3055\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 75ms/step - accuracy: 0.9631 - loss: 0.0926 - val_accuracy: 0.9051 - val_loss: 0.3064\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 110ms/step - accuracy: 0.9622 - loss: 0.0949 - val_accuracy: 0.9064 - val_loss: 0.2971\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 108ms/step - accuracy: 0.9655 - loss: 0.0869 - val_accuracy: 0.9071 - val_loss: 0.3114\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 109ms/step - accuracy: 0.9657 - loss: 0.0856 - val_accuracy: 0.9053 - val_loss: 0.3254\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 109ms/step - accuracy: 0.9680 - loss: 0.0803 - val_accuracy: 0.9034 - val_loss: 0.3440\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 109ms/step - accuracy: 0.9674 - loss: 0.0824 - val_accuracy: 0.9045 - val_loss: 0.3402\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KPKP_model_classification.keras and history to Histories\\KPKP_history_classification.pkl\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "Loaded KNKP position data with 900000 samples\n",
      "Loaded KNKP pair data with 450000 samples\n",
      "\n",
      "Training single model for KNKP\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 10ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 3.0576e-04 - val_mse: 3.0576e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 10ms/step - loss: 2.4703e-04 - mse: 2.4703e-04 - val_loss: 2.3355e-04 - val_mse: 2.3355e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 10ms/step - loss: 1.9293e-04 - mse: 1.9293e-04 - val_loss: 1.7643e-04 - val_mse: 1.7643e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 10ms/step - loss: 1.5463e-04 - mse: 1.5463e-04 - val_loss: 1.6968e-04 - val_mse: 1.6968e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m23907/23907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 11ms/step - loss: 1.4586e-04 - mse: 1.4586e-04 - val_loss: 1.4951e-04 - val_mse: 1.4951e-04\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 18ms/step - loss: 1.1444e-04 - mse: 1.1444e-04 - val_loss: 1.2292e-04 - val_mse: 1.2292e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 20ms/step - loss: 9.7037e-05 - mse: 9.7037e-05 - val_loss: 1.0185e-04 - val_mse: 1.0185e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 20ms/step - loss: 8.5760e-05 - mse: 8.5760e-05 - val_loss: 1.3966e-04 - val_mse: 1.3966e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 18ms/step - loss: 8.9115e-05 - mse: 8.9115e-05 - val_loss: 1.5064e-04 - val_mse: 1.5064e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 19ms/step - loss: 8.7115e-05 - mse: 8.7115e-05 - val_loss: 9.9049e-05 - val_mse: 9.9049e-05\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 34ms/step - loss: 6.3729e-05 - mse: 6.3729e-05 - val_loss: 8.2033e-05 - val_mse: 8.2033e-05\n",
      "Epoch 12/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 34ms/step - loss: 6.3215e-05 - mse: 6.3215e-05 - val_loss: 9.7620e-05 - val_mse: 9.7620e-05\n",
      "Epoch 13/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 34ms/step - loss: 5.0384e-05 - mse: 5.0384e-05 - val_loss: 1.0643e-04 - val_mse: 1.0643e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 34ms/step - loss: 6.0173e-05 - mse: 6.0173e-05 - val_loss: 7.9033e-05 - val_mse: 7.9033e-05\n",
      "Epoch 15/15\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 34ms/step - loss: 4.9590e-05 - mse: 4.9590e-05 - val_loss: 7.6657e-05 - val_mse: 7.6657e-05\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 64ms/step - loss: 3.9972e-05 - mse: 3.9972e-05 - val_loss: 8.3599e-05 - val_mse: 8.3599e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 63ms/step - loss: 4.7861e-05 - mse: 4.7861e-05 - val_loss: 7.8953e-05 - val_mse: 7.8953e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 62ms/step - loss: 3.8905e-05 - mse: 3.8905e-05 - val_loss: 8.2378e-05 - val_mse: 8.2378e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 64ms/step - loss: 3.6499e-05 - mse: 3.6499e-05 - val_loss: 7.4995e-05 - val_mse: 7.4995e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 64ms/step - loss: 3.6230e-05 - mse: 3.6230e-05 - val_loss: 7.5249e-05 - val_mse: 7.5249e-05\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 87ms/step - loss: 3.3278e-05 - mse: 3.3278e-05 - val_loss: 7.0967e-05 - val_mse: 7.0967e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 86ms/step - loss: 3.0535e-05 - mse: 3.0535e-05 - val_loss: 7.5016e-05 - val_mse: 7.5016e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 86ms/step - loss: 3.5273e-05 - mse: 3.5273e-05 - val_loss: 7.1197e-05 - val_mse: 7.1197e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 87ms/step - loss: 2.8777e-05 - mse: 2.8777e-05 - val_loss: 6.8765e-05 - val_mse: 6.8765e-05\n",
      "Epoch 25/25\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 87ms/step - loss: 2.8648e-05 - mse: 2.8648e-05 - val_loss: 6.7264e-05 - val_mse: 6.7264e-05\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Saved model to Models\\KNKP_model_single.keras and history to Histories\\KNKP_history_single.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step\n",
      "Single model thresholds: threshold=0.0123, Accuracy=0.9429\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6543 - loss: 0.8778 - val_accuracy: 0.8461 - val_loss: 0.5390\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8568 - loss: 0.4779 - val_accuracy: 0.8791 - val_loss: 0.3377\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.3126 - val_accuracy: 0.9151 - val_loss: 0.2468\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2367 - val_accuracy: 0.9412 - val_loss: 0.2025\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1961 - val_accuracy: 0.9487 - val_loss: 0.1842\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training regression model for KNKP\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 19ms/step - loss: 0.1561 - mse: 0.1561 - val_loss: 0.0899 - val_mse: 0.0899\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 20ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0733 - val_mse: 0.0733\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 20ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 21ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0619 - val_mse: 0.0619\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 18ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0592 - val_mse: 0.0592\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 35ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 34ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0528 - val_mse: 0.0528\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 35ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 35ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 35ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0523 - val_mse: 0.0523\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 62ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 61ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 61ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 61ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 61ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 146ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 154ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 154ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 154ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 154ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 206ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 205ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 214ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 214ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 214ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KNKP_model_regression.keras and history to Histories\\KNKP_history_regression.pkl\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 9ms/step\n",
      "Regression model thresholds: t1=-0.3940, t2=0.5025, Accuracy=0.9870\n",
      "Epoch 1/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.4245 - val_accuracy: 0.9859 - val_loss: 0.0638\n",
      "Epoch 2/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0592 - val_accuracy: 0.9860 - val_loss: 0.0633\n",
      "Epoch 3/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0597 - val_accuracy: 0.9862 - val_loss: 0.0634\n",
      "Epoch 4/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0601 - val_accuracy: 0.9859 - val_loss: 0.0646\n",
      "Epoch 5/5\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0597 - val_accuracy: 0.9861 - val_loss: 0.0634\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Updated threshold config saved to Configs\\thresholds.json\n",
      "\n",
      "Training classification model for KNKP\n",
      "Training with batch size: 32, epochs 1 to 5\n",
      "Epoch 1/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 32ms/step - accuracy: 0.8343 - loss: 0.3865 - val_accuracy: 0.9152 - val_loss: 0.2072\n",
      "Epoch 2/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 29ms/step - accuracy: 0.9163 - loss: 0.2057 - val_accuracy: 0.9308 - val_loss: 0.1706\n",
      "Epoch 3/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 31ms/step - accuracy: 0.9326 - loss: 0.1680 - val_accuracy: 0.9360 - val_loss: 0.1597\n",
      "Epoch 4/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 30ms/step - accuracy: 0.9423 - loss: 0.1456 - val_accuracy: 0.9437 - val_loss: 0.1427\n",
      "Epoch 5/5\n",
      "\u001b[1m11954/11954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 21ms/step - accuracy: 0.9485 - loss: 0.1294 - val_accuracy: 0.9390 - val_loss: 0.1542\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training with batch size: 64, epochs 6 to 10\n",
      "Epoch 6/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 29ms/step - accuracy: 0.9555 - loss: 0.1117 - val_accuracy: 0.9502 - val_loss: 0.1276\n",
      "Epoch 7/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 30ms/step - accuracy: 0.9610 - loss: 0.0988 - val_accuracy: 0.9501 - val_loss: 0.1284\n",
      "Epoch 8/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 28ms/step - accuracy: 0.9642 - loss: 0.0899 - val_accuracy: 0.9550 - val_loss: 0.1222\n",
      "Epoch 9/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 30ms/step - accuracy: 0.9676 - loss: 0.0822 - val_accuracy: 0.9512 - val_loss: 0.1281\n",
      "Epoch 10/10\n",
      "\u001b[1m5977/5977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 30ms/step - accuracy: 0.9705 - loss: 0.0758 - val_accuracy: 0.9574 - val_loss: 0.1168\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Training with batch size: 128, epochs 11 to 15\n",
      "Epoch 11/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 57ms/step - accuracy: 0.9787 - loss: 0.0550 - val_accuracy: 0.9602 - val_loss: 0.1158\n",
      "Epoch 12/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 53ms/step - accuracy: 0.9805 - loss: 0.0506 - val_accuracy: 0.9603 - val_loss: 0.1184\n",
      "Epoch 13/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 52ms/step - accuracy: 0.9822 - loss: 0.0468 - val_accuracy: 0.9605 - val_loss: 0.1241\n",
      "Epoch 14/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 57ms/step - accuracy: 0.9838 - loss: 0.0422 - val_accuracy: 0.9611 - val_loss: 0.1281\n",
      "Epoch 15/15\n",
      "\u001b[1m2989/2989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 57ms/step - accuracy: 0.9853 - loss: 0.0389 - val_accuracy: 0.9628 - val_loss: 0.1241\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Training with batch size: 256, epochs 16 to 20\n",
      "Epoch 16/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 102ms/step - accuracy: 0.9853 - loss: 0.0387 - val_accuracy: 0.9638 - val_loss: 0.1205\n",
      "Epoch 17/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 98ms/step - accuracy: 0.9873 - loss: 0.0334 - val_accuracy: 0.9621 - val_loss: 0.1284\n",
      "Epoch 18/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 103ms/step - accuracy: 0.9878 - loss: 0.0320 - val_accuracy: 0.9635 - val_loss: 0.1320\n",
      "Epoch 19/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 104ms/step - accuracy: 0.9889 - loss: 0.0289 - val_accuracy: 0.9643 - val_loss: 0.1340\n",
      "Epoch 20/20\n",
      "\u001b[1m1495/1495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 105ms/step - accuracy: 0.9901 - loss: 0.0259 - val_accuracy: 0.9642 - val_loss: 0.1353\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Training with batch size: 512, epochs 21 to 25\n",
      "Epoch 21/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 152ms/step - accuracy: 0.9896 - loss: 0.0283 - val_accuracy: 0.9657 - val_loss: 0.1360\n",
      "Epoch 22/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 151ms/step - accuracy: 0.9920 - loss: 0.0212 - val_accuracy: 0.9651 - val_loss: 0.1426\n",
      "Epoch 23/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 151ms/step - accuracy: 0.9913 - loss: 0.0233 - val_accuracy: 0.9662 - val_loss: 0.1403\n",
      "Epoch 24/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 151ms/step - accuracy: 0.9928 - loss: 0.0194 - val_accuracy: 0.9656 - val_loss: 0.1598\n",
      "Epoch 25/25\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 153ms/step - accuracy: 0.9921 - loss: 0.0215 - val_accuracy: 0.9656 - val_loss: 0.1599\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "Saved model to Models\\KNKP_model_classification.keras and history to Histories\\KNKP_history_classification.pkl\n",
      "Updated threshold config saved to Configs\\thresholds.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KRK': {'single': {'threshold1': 0.0005025125628140704, 'threshold2': 0.0},\n",
       "  'regression': {'threshold1': -0.5829145728643217,\n",
       "   'threshold2': 0.46633165829145734},\n",
       "  'classification': {'threshold1': 0.0, 'threshold2': 0.0}},\n",
       " 'KQKR': {'single': {'threshold1': 0.0020100502512562816, 'threshold2': 0.0},\n",
       "  'regression': {'threshold1': -0.16884422110552766,\n",
       "   'threshold2': 0.3216080402010051},\n",
       "  'classification': {'threshold1': 0.0, 'threshold2': 0.0}},\n",
       " 'KRKP': {'single': {'threshold1': 0.0, 'threshold2': 0.0},\n",
       "  'regression': {'threshold1': -0.31758793969849247,\n",
       "   'threshold2': 0.36180904522613067},\n",
       "  'classification': {'threshold1': 0.0, 'threshold2': 0.0}},\n",
       " 'KPK': {'single': {'threshold1': 0.004271356783919598, 'threshold2': 0.0},\n",
       "  'regression': {'threshold1': -0.4984924623115578,\n",
       "   'threshold2': 0.43015075376884426},\n",
       "  'classification': {'threshold1': 0.0, 'threshold2': 0.0}},\n",
       " 'KPKP': {'single': {'threshold1': 0.00628140703517588, 'threshold2': 0.0},\n",
       "  'regression': {'threshold1': -0.48643216080402013,\n",
       "   'threshold2': 0.49849246231155786},\n",
       "  'classification': {'threshold1': 0.0, 'threshold2': 0.0}},\n",
       " 'KNKP': {'single': {'threshold1': 0.012311557788944725, 'threshold2': 0.0},\n",
       "  'regression': {'threshold1': -0.3939698492462312,\n",
       "   'threshold2': 0.5025125628140704},\n",
       "  'classification': {'threshold1': 0.0, 'threshold2': 0.0}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endgames = ['KRK', 'KQKR', 'KRKP', 'KPK','KPKP', 'KNKP']\n",
    "model_types = [\n",
    "    (\"single\", lambda n: create_single_input_model(n)),\n",
    "    (\"regression\", lambda n: create_pairwise_model(\"Regression\", n)),\n",
    "    (\"classification\", lambda n: create_pairwise_model(\"Classification\", n)),\n",
    "]\n",
    "train_endgame_models(endgames, model_types, force_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310d2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

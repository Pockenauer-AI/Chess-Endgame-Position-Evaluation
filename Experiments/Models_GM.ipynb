{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946e6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, Model, Sequential, backend, optimizers, config\n",
    "from tensorflow.keras.layers import Input, LeakyReLU\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "config.enable_unsafe_deserialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f14297",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594d80ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 64, 128, 256, 512]\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [int(32*(2**i)) for i in range(5)]\n",
    "\n",
    "print(batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95cb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_cnn(n_pieces):\n",
    "    # Use Input layer to define the input shape\n",
    "    inputs = Input(shape=(n_pieces,8, 8))  \n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6ecfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6d0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_input_model(n_pieces):\n",
    "    inputs = Input(shape=(n_pieces, 8, 8))\n",
    "    base_cnn = create_base_cnn(n_pieces) \n",
    "    x = base_cnn(inputs) \n",
    "    x = layers.Dense(64)(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.Dense(1, activation='tanh')(x) # Output between -1 and 1\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba3424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairwise_model(version, n_pieces):\n",
    "    base_cnn = create_base_cnn(n_pieces) \n",
    "    input_a = Input(shape=(n_pieces,8, 8)) \n",
    "    input_b = Input(shape=(n_pieces,8, 8))\n",
    "\n",
    "    encoded_a = base_cnn(input_a)\n",
    "    encoded_b = base_cnn(input_b)\n",
    "\n",
    "    diff = layers.Subtract()([encoded_a, encoded_b])\n",
    "    mult = layers.Multiply()([encoded_a, encoded_b])\n",
    "    merged = layers.Concatenate()([diff, mult])\n",
    "\n",
    "    x = layers.Dense(128)(merged)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "    x = layers.Dense(32)(x)\n",
    "    x = LeakyReLU(negative_slope=0.1)(x)\n",
    "\n",
    "    if version == \"Regression\":\n",
    "        output = layers.Dense(1, activation='tanh')(x) #Output between -1 and 1 \n",
    "        loss = 'mse'\n",
    "        metrics = ['mse']\n",
    "    elif version == \"Classification\":\n",
    "        output = layers.Dense(3, activation='softmax')(x)\n",
    "        loss = SparseCategoricalCrossentropy()\n",
    "        metrics = ['accuracy']\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown version: {version}\")\n",
    "\n",
    "    model = Model(inputs=[input_a, input_b], outputs=output)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr), loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0509f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_v1(X1, X2, y_true):\n",
    "    # Finds the best threshold by maximizing accuracy\n",
    "    best_threshold, best_score = None, 0\n",
    "\n",
    "    thresholds = np.linspace(0, 0.1, 200)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = np.where(np.abs(X1 - X2) < threshold, 0, np.where(X1 > X2, 1, 2)) #Help: Maybe swap 0 and 1\n",
    "        score = accuracy_score(y_true, y_pred)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c7f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_thresholds_v2(X, y_true):\n",
    "    # Finds the best threshold1 and threshold2 using a grid search by maximizing accuracy\n",
    "    thresholds1 = np.linspace(-0.8, 0, 200)\n",
    "    thresholds2 = np.linspace(0, 0.8, 200)\n",
    "\n",
    "    best_t1, best_t2, best_acc = None, None, 0\n",
    "\n",
    "    for t1 in thresholds1:\n",
    "        for t2 in thresholds2:\n",
    "            if t1 >= t2:  \n",
    "                continue\n",
    "\n",
    "            y_pred = np.where(X > t2, 2, np.where(X < t1, 1, 0)) #Help: Maybe swap 0 and 1\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            if acc > best_acc:\n",
    "                best_t1, best_t2, best_acc = t1, t2, acc\n",
    "\n",
    "    return best_t1, best_t2, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f2d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_post_nn(n):\n",
    "    model = Sequential([\n",
    "        layers.Input(shape=(n,)),\n",
    "        layers.Dense(8),\n",
    "        layers.LeakyReLU(negative_slope=0.1),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=lr),\n",
    "        loss=SparseCategoricalCrossentropy(),  \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647ee8c",
   "metadata": {},
   "source": [
    "**FOR ALL MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a28f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, X, y, epochs_per_batch=3, acc=False):\n",
    "    hist = {\n",
    "        'loss': [],\n",
    "        'val_loss': [],\n",
    "        }  \n",
    "    if acc:\n",
    "        hist['accuracy'] = []\n",
    "        hist['val_accuracy'] = []\n",
    "         \n",
    "    # EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5, # stop if val_loss doesn’t improve after 5 epochs\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    for n, batch_size in enumerate(batch_sizes):\n",
    "        print(f\"Batchsize: {batch_size}\")\n",
    "        print(f\"Starting with epoch: {n*epochs_per_batch}\")\n",
    "        # Train your model with the current batch size\n",
    "        epoch_history = model.fit(\n",
    "            X, y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=(n+1)*epochs_per_batch,\n",
    "            initial_epoch=n*epochs_per_batch,  \n",
    "            validation_split=0.15,\n",
    "            verbose=1,\n",
    "            callbacks = [early_stopping]\n",
    "        )\n",
    "\n",
    "        # Append the results to the history dictionary\n",
    "        hist['loss'].extend(epoch_history.history['loss'])\n",
    "        hist['val_loss'].extend(epoch_history.history['val_loss'])\n",
    "        if acc:\n",
    "            hist['accuracy'].extend(epoch_history.history['accuracy'])\n",
    "            hist['val_accuracy'].extend(epoch_history.history['val_accuracy'])\n",
    "        if model.stop_training:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "        \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aae39c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Mixed data with 500000 samples\n",
      "Loaded Mixed pairs data with 180000 samples\n",
      "\n",
      "Training single model for Mixed\n",
      "Batchsize: 32\n",
      "Starting with epoch: 0\n",
      "Epoch 1/3\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 2/3\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 3/3\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Batchsize: 64\n",
      "Starting with epoch: 3\n",
      "Epoch 4/6\n",
      "\u001b[1m6641/6641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 8ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5/6\n",
      "\u001b[1m6641/6641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 9ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6/6\n",
      "\u001b[1m6641/6641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Batchsize: 128\n",
      "Starting with epoch: 6\n",
      "Epoch 7/9\n",
      "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8/9\n",
      "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9/9\n",
      "\u001b[1m3321/3321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Batchsize: 256\n",
      "Starting with epoch: 9\n",
      "Epoch 10/12\n",
      "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11/12\n",
      "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12/12\n",
      "\u001b[1m1661/1661\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Batchsize: 512\n",
      "Starting with epoch: 12\n",
      "Epoch 13/15\n",
      "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 42ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14/15\n",
      "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 41ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 15/15\n",
      "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 41ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "Best threshold: 0.0191, Accuracy: 0.7551\n",
      "Epoch 1/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6342 - loss: 0.9045 - val_accuracy: 0.7963 - val_loss: 0.6608\n",
      "Epoch 2/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7990 - loss: 0.6379 - val_accuracy: 0.7937 - val_loss: 0.5721\n",
      "Epoch 3/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8006 - loss: 0.5561 - val_accuracy: 0.7960 - val_loss: 0.5226\n",
      "Epoch 4/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7955 - loss: 0.5228 - val_accuracy: 0.7978 - val_loss: 0.5021\n",
      "Epoch 5/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4974 - val_accuracy: 0.7983 - val_loss: 0.4955\n",
      "Epoch 6/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7987 - loss: 0.4978 - val_accuracy: 0.7999 - val_loss: 0.4929\n",
      "Epoch 7/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7976 - loss: 0.4955 - val_accuracy: 0.8009 - val_loss: 0.4914\n",
      "Epoch 8/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7991 - loss: 0.4891 - val_accuracy: 0.8001 - val_loss: 0.4903\n",
      "Epoch 9/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7977 - loss: 0.4905 - val_accuracy: 0.7972 - val_loss: 0.4911\n",
      "Epoch 10/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7963 - loss: 0.4950 - val_accuracy: 0.7936 - val_loss: 0.4933\n",
      "WARNING:tensorflow:From c:\\Users\\pocke\\miniconda3\\envs\\speed\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "Training regression model for Mixed\n",
      "Batchsize: 32\n",
      "Starting with epoch: 0\n",
      "Epoch 1/3\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - loss: 0.6355 - mse: 0.6355 - val_loss: 0.4151 - val_mse: 0.4151\n",
      "Epoch 2/3\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - loss: 0.3802 - mse: 0.3802 - val_loss: 0.3398 - val_mse: 0.3398\n",
      "Epoch 3/3\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - loss: 0.3081 - mse: 0.3081 - val_loss: 0.2995 - val_mse: 0.2995\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Batchsize: 64\n",
      "Starting with epoch: 3\n",
      "Epoch 4/6\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12ms/step - loss: 0.2390 - mse: 0.2390 - val_loss: 0.2759 - val_mse: 0.2759\n",
      "Epoch 5/6\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12ms/step - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2644 - val_mse: 0.2644\n",
      "Epoch 6/6\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12ms/step - loss: 0.2009 - mse: 0.2009 - val_loss: 0.2499 - val_mse: 0.2499\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Batchsize: 128\n",
      "Starting with epoch: 6\n",
      "Epoch 7/9\n",
      "\u001b[1m1196/1196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 21ms/step - loss: 0.1626 - mse: 0.1626 - val_loss: 0.2451 - val_mse: 0.2451\n",
      "Epoch 8/9\n",
      "\u001b[1m1196/1196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - loss: 0.1458 - mse: 0.1458 - val_loss: 0.2481 - val_mse: 0.2481\n",
      "Epoch 9/9\n",
      "\u001b[1m1196/1196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - loss: 0.1377 - mse: 0.1377 - val_loss: 0.2521 - val_mse: 0.2521\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Batchsize: 256\n",
      "Starting with epoch: 9\n",
      "Epoch 10/12\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 39ms/step - loss: 0.1308 - mse: 0.1308 - val_loss: 0.2444 - val_mse: 0.2444\n",
      "Epoch 11/12\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 39ms/step - loss: 0.1135 - mse: 0.1135 - val_loss: 0.2402 - val_mse: 0.2402\n",
      "Epoch 12/12\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 39ms/step - loss: 0.1072 - mse: 0.1072 - val_loss: 0.2492 - val_mse: 0.2492\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Batchsize: 512\n",
      "Starting with epoch: 12\n",
      "Epoch 13/15\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 79ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 0.2487 - val_mse: 0.2487\n",
      "Epoch 14/15\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 79ms/step - loss: 0.0787 - mse: 0.0787 - val_loss: 0.2601 - val_mse: 0.2601\n",
      "Epoch 15/15\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 79ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.2624 - val_mse: 0.2624\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step\n",
      "Best thresholds: t1=-0.2693, t2=0.1970, Accuracy: 0.9486\n",
      "Epoch 1/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7840 - loss: 0.5134 - val_accuracy: 0.9495 - val_loss: 0.1962\n",
      "Epoch 2/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.2028 - val_accuracy: 0.9494 - val_loss: 0.1893\n",
      "Epoch 3/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.2008 - val_accuracy: 0.9479 - val_loss: 0.1890\n",
      "Epoch 4/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1993 - val_accuracy: 0.9485 - val_loss: 0.1888\n",
      "Epoch 5/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.1975 - val_accuracy: 0.9491 - val_loss: 0.1885\n",
      "Epoch 6/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1985 - val_accuracy: 0.9485 - val_loss: 0.1887\n",
      "Epoch 7/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1975 - val_accuracy: 0.9485 - val_loss: 0.1884\n",
      "Epoch 8/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2028 - val_accuracy: 0.9495 - val_loss: 0.1887\n",
      "Epoch 9/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1975 - val_accuracy: 0.9494 - val_loss: 0.1882\n",
      "Epoch 10/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1981 - val_accuracy: 0.9487 - val_loss: 0.1883\n",
      "\n",
      "Training classification model for Mixed\n",
      "Batchsize: 32\n",
      "Starting with epoch: 0\n",
      "Epoch 1/3\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.6455 - loss: 0.7661 - val_accuracy: 0.7994 - val_loss: 0.4787\n",
      "Epoch 2/3\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8170 - loss: 0.4538 - val_accuracy: 0.8391 - val_loss: 0.4026\n",
      "Epoch 3/3\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8550 - loss: 0.3663 - val_accuracy: 0.8622 - val_loss: 0.3511\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Batchsize: 64\n",
      "Starting with epoch: 3\n",
      "Epoch 4/6\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12ms/step - accuracy: 0.8881 - loss: 0.2941 - val_accuracy: 0.8811 - val_loss: 0.3083\n",
      "Epoch 5/6\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12ms/step - accuracy: 0.8957 - loss: 0.2726 - val_accuracy: 0.8839 - val_loss: 0.3004\n",
      "Epoch 6/6\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 12ms/step - accuracy: 0.9022 - loss: 0.2569 - val_accuracy: 0.8875 - val_loss: 0.2923\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Batchsize: 128\n",
      "Starting with epoch: 6\n",
      "Epoch 7/9\n",
      "\u001b[1m1196/1196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 21ms/step - accuracy: 0.9178 - loss: 0.2202 - val_accuracy: 0.8918 - val_loss: 0.2848\n",
      "Epoch 8/9\n",
      "\u001b[1m1196/1196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 21ms/step - accuracy: 0.9245 - loss: 0.2045 - val_accuracy: 0.8949 - val_loss: 0.2893\n",
      "Epoch 9/9\n",
      "\u001b[1m1196/1196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 21ms/step - accuracy: 0.9294 - loss: 0.1916 - val_accuracy: 0.8900 - val_loss: 0.2995\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Batchsize: 256\n",
      "Starting with epoch: 9\n",
      "Epoch 10/12\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 41ms/step - accuracy: 0.9319 - loss: 0.1829 - val_accuracy: 0.8957 - val_loss: 0.2888\n",
      "Epoch 11/12\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step - accuracy: 0.9378 - loss: 0.1692 - val_accuracy: 0.8959 - val_loss: 0.2934\n",
      "Epoch 12/12\n",
      "\u001b[1m598/598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 40ms/step - accuracy: 0.9412 - loss: 0.1592 - val_accuracy: 0.8932 - val_loss: 0.3031\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Batchsize: 512\n",
      "Starting with epoch: 12\n",
      "Epoch 13/15\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - accuracy: 0.9417 - loss: 0.1604 - val_accuracy: 0.8970 - val_loss: 0.3001\n",
      "Epoch 14/15\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 79ms/step - accuracy: 0.9470 - loss: 0.1441 - val_accuracy: 0.8960 - val_loss: 0.3133\n",
      "Epoch 15/15\n",
      "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 79ms/step - accuracy: 0.9497 - loss: 0.1375 - val_accuracy: 0.8943 - val_loss: 0.3275\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    }
   ],
   "source": [
    "threshold_config = {}\n",
    "endgame = \"Mixed\"\n",
    "model_types = [\n",
    "    (\"single\", create_single_input_model),  # (name, create_func)\n",
    "    (\"regression\", lambda n: create_pairwise_model(\"Regression\", n)),\n",
    "    (\"classification\", lambda n: create_pairwise_model(\"Classification\", n)),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#Load the data\n",
    "data = np.load(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\DataBase\\{endgame}_position_train_val.npz\")\n",
    "positions, dtm_values = data[\"X\"][:500000], data[\"y\"][:500000]\n",
    "print(f\"Loaded {endgame} data with {dtm_values.shape[0]} samples\")\n",
    "\n",
    "pairs_data = np.load(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Database\\{endgame}_pairs_train_val.npz\")\n",
    "X1, X2, y = pairs_data[\"X1\"][:500000], pairs_data[\"X2\"][:500000], pairs_data[\"y\"][:500000]\n",
    "print(f\"Loaded {endgame} pairs data with {y.shape[0]} samples\")\n",
    "\n",
    "for model_name, create_func in model_types:\n",
    "    #Help: Check if model already exists\n",
    "    model_path = f\"C:/SPEICHER/Bachelor_Thesis/Experiments/Models/{endgame}_model_{model_name}.keras\"\n",
    "    if os.path.exists(model_path) and False:\n",
    "        print(f\"Skipping {model_name}, already trained.\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nTraining {model_name} model for {endgame}\")\n",
    "\n",
    "    # Create model\n",
    "    model = create_func(positions.shape[1]) #Help: [1]\n",
    "    # model.summary()\n",
    "\n",
    "    #Help: Maybe different mapping\n",
    "    y_trans = np.where(y==1, -1, np.where(y==2, 1, 0))  # -1 = pos1 better, 0 = roughly equal, 1 = pos2 better\n",
    "\n",
    "    # Choose inputs\n",
    "    if model_name == \"single\":\n",
    "        model, history = training(model, positions, dtm_values)\n",
    "    elif model_name == \"regression\":\n",
    "        model, history = training(model, [X1, X2], y_trans)\n",
    "    else:\n",
    "        model, history = training(model, [X1, X2], y, acc=True)\n",
    "\n",
    "    # Save model and history\n",
    "    model.save(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Models\\{endgame}_model_{model_name}.keras\")\n",
    "    with open(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Histories\\{endgame}_history_{model_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(history, f)\n",
    "\n",
    "    # Post-processing for single-input model\n",
    "    if model_name == \"single\":\n",
    "        # Predictions\n",
    "        y1_pred = model.predict(X1[:100000])\n",
    "        y2_pred = model.predict(X2[:100000])\n",
    "        y_pred_comb = np.hstack([y1_pred, y2_pred])\n",
    "\n",
    "        # Threshold method\n",
    "        best_threshold, best_accuracy = find_best_threshold_v1(y1_pred, y2_pred, y[:100000])\n",
    "        print(f\"Best threshold: {best_threshold:.4f}, Accuracy: {best_accuracy:.4f}\")\n",
    "        threshold_config.setdefault(endgame, {})[model_name] = {\"threshold1\": float(best_threshold),\"threshold2\": float(0)}\n",
    "        # Nerual Network\n",
    "        model = create_post_nn(2)\n",
    "        # model.summary()\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        model.fit(y_pred_comb, y[:100000], epochs=10, batch_size=32, validation_split=0.15, callbacks=[early_stopping])\n",
    "        model.save(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Models\\{endgame}_model_pro_{model_name}.keras\")\n",
    "\n",
    "    elif model_name == \"regression\":\n",
    "        # Predictions\n",
    "        y_pred = model.predict([X1[:100000], X2[:100000]])\n",
    "        \n",
    "        # Threshold method\n",
    "        best_t1, best_t2, best_acc = find_best_thresholds_v2(y_pred, y[:100000])\n",
    "        print(f\"Best thresholds: t1={best_t1:.4f}, t2={best_t2:.4f}, Accuracy: {best_acc:.4f}\")\n",
    "        threshold_config.setdefault(endgame, {})[model_name] = {\"threshold1\": float(best_t1),\"threshold2\": float(best_t2)}\n",
    "        # Nerual Network\n",
    "        model = create_post_nn(1)\n",
    "        # model.summary()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        model.fit(y_pred, y[:100000], epochs=10, batch_size=32, validation_split=0.15, callbacks=[early_stopping])\n",
    "        model.save(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Models\\{endgame}_model_pro_{model_name}.keras\")\n",
    "\n",
    "    backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "with open(r\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Configs\\Mixed_thresholds.json\", \"w\") as f:\n",
    "    json.dump(threshold_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820c742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946e6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from keras import layers, Input\n",
    "import pickle\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "import gc\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f14297",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594d80ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 64, 128, 256, 512]\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [int(32*(2**i)) for i in range(5)]\n",
    "\n",
    "print(batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95cb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_cnn(n_pieces):\n",
    "    # Use Input layer to define the input shape\n",
    "    inputs = Input(shape=(n_pieces, 8, 8))  #Help: n_pieces, 8, 8!\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6ecfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6d0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_input_model(n_pieces):\n",
    "    inputs = Input(shape=(n_pieces, 8, 8)) #Help: n_pieces, 8, 8!\n",
    "    base_cnn = create_base_cnn(n_pieces) \n",
    "    x = base_cnn(inputs) \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(1, activation='tanh')(x) # Output between -1 and 1\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=x)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba3424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairwise_model(version, n_pieces):\n",
    "    base_cnn = create_base_cnn(n_pieces) \n",
    "    input_a = Input(shape=(n_pieces, 8, 8)) #Help: n_pieces, 8, 8!\n",
    "    input_b = Input(shape=(n_pieces, 8, 8))\n",
    "\n",
    "    encoded_a = base_cnn(input_a)\n",
    "    encoded_b = base_cnn(input_b)\n",
    "\n",
    "    diff = layers.Subtract()([encoded_a, encoded_b])\n",
    "    mult = layers.Multiply()([encoded_a, encoded_b])\n",
    "    merged = layers.Concatenate()([diff, mult])\n",
    "\n",
    "    x = layers.Dense(128, activation='relu')(merged)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "    if version == \"Regression\":\n",
    "        output = layers.Dense(1, activation='tanh')(x) #Output between -1 and 1 #Help: use sigmoid for labels 0,1,2\n",
    "        # output = layers.Lambda(lambda x: x * 2)(output)\n",
    "        loss = 'mse'\n",
    "        metrics = ['mse']\n",
    "    elif version == \"Classification\":\n",
    "        output = layers.Dense(3, activation='softmax')(x)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        metrics = ['accuracy']\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown version: {version}\")\n",
    "\n",
    "    model = keras.Model(inputs=[input_a, input_b], outputs=output)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0509f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_v1(X1, X2, y_true):\n",
    "    # Finds the best threshold by maximizing accuracy\n",
    "    best_threshold, best_score = None, 0\n",
    "\n",
    "    thresholds = np.linspace(0, 0.1, 200)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred = np.where(np.abs(X1 - X2) < threshold, 0, np.where(X1 > X2, 1, 2)) #Help: Maybe swap 0 and 1\n",
    "        score = accuracy_score(y_true, y_pred)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c7f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_thresholds_v2(X, y_true):\n",
    "    # Finds the best threshold1 and threshold2 using a grid search by maximizing accuracy\n",
    "    thresholds1 = np.linspace(-0.8, 0, 200)\n",
    "    thresholds2 = np.linspace(0, 0.8, 200)\n",
    "\n",
    "    best_t1, best_t2, best_acc = None, None, 0\n",
    "\n",
    "    for t1 in thresholds1:\n",
    "        for t2 in thresholds2:\n",
    "            if t1 >= t2:  \n",
    "                continue\n",
    "\n",
    "            y_pred = np.where(X > t2, 2, np.where(X < t1, 1, 0)) #Help: Maybe swap 0 and 1\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            if acc > best_acc:\n",
    "                best_t1, best_t2, best_acc = t1, t2, acc\n",
    "\n",
    "    return best_t1, best_t2, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f2d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_post_nn(n):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(16, activation='relu', input_shape=(n,)),  \n",
    "        layers.Dense(8, activation='relu'),  \n",
    "        layers.Dense(3, activation='softmax') \n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),  \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647ee8c",
   "metadata": {},
   "source": [
    "**FOR ALL MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a28f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, X, y, epochs_per_batch=6, acc=False):\n",
    "    hist = {\n",
    "        'loss': [],\n",
    "        'val_loss': [],\n",
    "        }  \n",
    "    if acc:\n",
    "        hist['accuracy'] = []\n",
    "        hist['val_accuracy'] = []\n",
    "         \n",
    "    # EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5, # stop if val_loss doesn’t improve after 5 epochs\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    if y.shape[0] < 1_000_000:\n",
    "        # make size larger for better training\n",
    "        factor = 1_000_000// y.shape[0]\n",
    "        X = np.tile(X, (factor, 1, 1, 1))\n",
    "        y = np.tile(y,factor)\n",
    "        indices = np.random.permutation(y.shape[0])\n",
    "        X = X[indices]\n",
    "        y = y[indices]\n",
    "\n",
    "\n",
    "    for n, batch_size in enumerate(batch_sizes):\n",
    "        print(f\"Batchsize: {batch_size}\")\n",
    "        print(f\"Starting with epoch: {n*epochs_per_batch}\")\n",
    "        # Train your model with the current batch size\n",
    "        epoch_history = model.fit(\n",
    "            X, y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=(n+1)*epochs_per_batch,\n",
    "            initial_epoch=n*epochs_per_batch,  \n",
    "            validation_split=0.15,\n",
    "            verbose=1,\n",
    "            callbacks = [early_stopping]\n",
    "        )\n",
    "\n",
    "        # Append the results to the history dictionary\n",
    "        hist['loss'].extend(epoch_history.history['loss'])\n",
    "        hist['val_loss'].extend(epoch_history.history['val_loss'])\n",
    "        if acc:\n",
    "            hist['accuracy'].extend(epoch_history.history['accuracy'])\n",
    "            hist['val_accuracy'].extend(epoch_history.history['val_accuracy'])\n",
    "        if model.stop_training:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "        \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae39c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing endgame: KRK\n",
      "Loaded KRK data with 50500 samples\n",
      "Loaded KRK pairs data with 4500000 samples\n",
      "Skipping single, already trained.\n",
      "Skipping regression, already trained.\n",
      "Skipping classification, already trained.\n",
      "Processing endgame: KQKR\n",
      "Loaded KQKR data with 3074198 samples\n",
      "Loaded KQKR pairs data with 4500000 samples\n",
      "Skipping single, already trained.\n",
      "Skipping regression, already trained.\n",
      "Skipping classification, already trained.\n",
      "Processing endgame: KPKR\n",
      "Loaded KPKR data with 4500000 samples\n",
      "Loaded KPKR pairs data with 4500000 samples\n",
      "Skipping single, already trained.\n",
      "Skipping regression, already trained.\n",
      "Skipping classification, already trained.\n",
      "Processing endgame: KPK\n",
      "Loaded KPK data with 151221 samples\n",
      "Loaded KPK pairs data with 4500000 samples\n",
      "\n",
      "Training single model for KPK\n",
      "Batchsize: 32\n",
      "Starting with epoch: 0\n",
      "Epoch 1/6\n",
      "\u001b[1m24101/24101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.4606e-04 - val_mse: 1.4606e-04\n",
      "Epoch 2/6\n",
      "\u001b[1m24101/24101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4ms/step - loss: 1.9001e-04 - mse: 1.9001e-04 - val_loss: 1.7673e-04 - val_mse: 1.7673e-04\n",
      "Epoch 3/6\n",
      "\u001b[1m24101/24101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4ms/step - loss: 1.2784e-04 - mse: 1.2784e-04 - val_loss: 7.0742e-05 - val_mse: 7.0742e-05\n",
      "Epoch 4/6\n",
      "\u001b[1m24101/24101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4ms/step - loss: 8.8623e-05 - mse: 8.8623e-05 - val_loss: 5.1159e-05 - val_mse: 5.1159e-05\n",
      "Epoch 5/6\n",
      "\u001b[1m24101/24101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4ms/step - loss: 6.4528e-05 - mse: 6.4528e-05 - val_loss: 6.3028e-05 - val_mse: 6.3028e-05\n",
      "Epoch 6/6\n",
      "\u001b[1m24101/24101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4ms/step - loss: 6.2101e-05 - mse: 6.2101e-05 - val_loss: 4.3420e-05 - val_mse: 4.3420e-05\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Batchsize: 64\n",
      "Starting with epoch: 6\n",
      "Epoch 7/12\n",
      "\u001b[1m12051/12051\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - loss: 3.1512e-05 - mse: 3.1512e-05 - val_loss: 2.6394e-05 - val_mse: 2.6394e-05\n",
      "Epoch 8/12\n",
      "\u001b[1m12051/12051\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - loss: 3.8691e-05 - mse: 3.8691e-05 - val_loss: 1.9887e-05 - val_mse: 1.9887e-05\n",
      "Epoch 9/12\n",
      "\u001b[1m12051/12051\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - loss: 2.4086e-05 - mse: 2.4086e-05 - val_loss: 2.2889e-05 - val_mse: 2.2889e-05\n",
      "Epoch 10/12\n",
      "\u001b[1m12051/12051\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6ms/step - loss: 2.2977e-05 - mse: 2.2977e-05 - val_loss: 2.0255e-05 - val_mse: 2.0255e-05\n",
      "Epoch 11/12\n",
      "\u001b[1m12051/12051\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6ms/step - loss: 2.0262e-05 - mse: 2.0262e-05 - val_loss: 3.1041e-05 - val_mse: 3.1041e-05\n",
      "Epoch 12/12\n",
      "\u001b[1m12051/12051\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6ms/step - loss: 2.0205e-05 - mse: 2.0205e-05 - val_loss: 1.9550e-05 - val_mse: 1.9550e-05\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Batchsize: 128\n",
      "Starting with epoch: 12\n",
      "Epoch 13/18\n",
      "\u001b[1m6026/6026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 8ms/step - loss: 1.3269e-05 - mse: 1.3269e-05 - val_loss: 1.1614e-05 - val_mse: 1.1614e-05\n",
      "Epoch 14/18\n",
      "\u001b[1m6026/6026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 8ms/step - loss: 1.5832e-05 - mse: 1.5832e-05 - val_loss: 1.4054e-05 - val_mse: 1.4054e-05\n",
      "Epoch 15/18\n",
      "\u001b[1m6026/6026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 8ms/step - loss: 1.1716e-05 - mse: 1.1716e-05 - val_loss: 2.1007e-05 - val_mse: 2.1007e-05\n",
      "Epoch 16/18\n",
      "\u001b[1m6026/6026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 8ms/step - loss: 1.3146e-05 - mse: 1.3146e-05 - val_loss: 1.3175e-05 - val_mse: 1.3175e-05\n",
      "Epoch 17/18\n",
      "\u001b[1m6026/6026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 8ms/step - loss: 1.1613e-05 - mse: 1.1613e-05 - val_loss: 1.2699e-05 - val_mse: 1.2699e-05\n",
      "Epoch 18/18\n",
      "\u001b[1m6026/6026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 8ms/step - loss: 1.1040e-05 - mse: 1.1040e-05 - val_loss: 1.0922e-05 - val_mse: 1.0922e-05\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Batchsize: 256\n",
      "Starting with epoch: 18\n",
      "Epoch 19/24\n",
      "\u001b[1m3013/3013\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - loss: 8.5248e-06 - mse: 8.5248e-06 - val_loss: 8.0059e-06 - val_mse: 8.0059e-06\n",
      "Epoch 20/24\n",
      "\u001b[1m3013/3013\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - loss: 7.4893e-06 - mse: 7.4893e-06 - val_loss: 7.2779e-06 - val_mse: 7.2779e-06\n",
      "Epoch 21/24\n",
      "\u001b[1m3013/3013\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - loss: 7.1714e-06 - mse: 7.1714e-06 - val_loss: 8.2647e-06 - val_mse: 8.2647e-06\n",
      "Epoch 22/24\n",
      "\u001b[1m3013/3013\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - loss: 7.4124e-06 - mse: 7.4124e-06 - val_loss: 6.9266e-06 - val_mse: 6.9266e-06\n",
      "Epoch 23/24\n",
      "\u001b[1m3013/3013\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - loss: 6.5193e-06 - mse: 6.5193e-06 - val_loss: 7.0738e-06 - val_mse: 7.0738e-06\n",
      "Epoch 24/24\n",
      "\u001b[1m3013/3013\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step - loss: 6.3233e-06 - mse: 6.3233e-06 - val_loss: 6.2891e-06 - val_mse: 6.2891e-06\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Batchsize: 512\n",
      "Starting with epoch: 24\n",
      "Epoch 25/30\n",
      "\u001b[1m1507/1507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 5.1423e-06 - mse: 5.1423e-06 - val_loss: 5.2635e-06 - val_mse: 5.2635e-06\n",
      "Epoch 26/30\n",
      "\u001b[1m1507/1507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 4.6841e-06 - mse: 4.6841e-06 - val_loss: 5.7775e-06 - val_mse: 5.7775e-06\n",
      "Epoch 27/30\n",
      "\u001b[1m1507/1507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 5.0537e-06 - mse: 5.0537e-06 - val_loss: 4.9397e-06 - val_mse: 4.9397e-06\n",
      "Epoch 28/30\n",
      "\u001b[1m1507/1507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 4.4408e-06 - mse: 4.4408e-06 - val_loss: 4.9130e-06 - val_mse: 4.9130e-06\n",
      "Epoch 29/30\n",
      "\u001b[1m1507/1507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 4.4234e-06 - mse: 4.4234e-06 - val_loss: 4.4514e-06 - val_mse: 4.4514e-06\n",
      "Epoch 30/30\n",
      "\u001b[1m1507/1507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 4.4953e-06 - mse: 4.4953e-06 - val_loss: 4.9559e-06 - val_mse: 4.9559e-06\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "Best threshold: 0.0020, Accuracy: 0.9817\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pocke\\miniconda3\\envs\\speed\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8576 - loss: 0.5414 - val_accuracy: 0.9579 - val_loss: 0.1407\n",
      "Epoch 2/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1235 - val_accuracy: 0.9671 - val_loss: 0.1050\n",
      "Epoch 3/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9704 - loss: 0.0918 - val_accuracy: 0.9723 - val_loss: 0.0822\n",
      "Epoch 4/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9746 - loss: 0.0756 - val_accuracy: 0.9743 - val_loss: 0.0735\n",
      "Epoch 5/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9768 - loss: 0.0696 - val_accuracy: 0.9757 - val_loss: 0.0663\n",
      "Epoch 6/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9765 - loss: 0.0682 - val_accuracy: 0.9740 - val_loss: 0.0723\n",
      "Epoch 7/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9784 - loss: 0.0632 - val_accuracy: 0.9797 - val_loss: 0.0595\n",
      "Epoch 8/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9789 - loss: 0.0628 - val_accuracy: 0.9801 - val_loss: 0.0581\n",
      "Epoch 9/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9793 - loss: 0.0624 - val_accuracy: 0.9776 - val_loss: 0.0580\n",
      "Epoch 10/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9795 - loss: 0.0560 - val_accuracy: 0.9801 - val_loss: 0.0532\n",
      "WARNING:tensorflow:From c:\\Users\\pocke\\miniconda3\\envs\\speed\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "Training regression model for KPK\n",
      "Batchsize: 32\n",
      "Starting with epoch: 0\n",
      "Epoch 1/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 5ms/step - loss: 0.0810 - mse: 0.0810 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 2/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 5ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 5ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 5ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 5ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 5ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Batchsize: 64\n",
      "Starting with epoch: 6\n",
      "Epoch 7/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 7ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 8/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 7ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 9/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 7ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 10/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 7ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 11/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 7ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 12/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 7ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Batchsize: 128\n",
      "Starting with epoch: 12\n",
      "Epoch 13/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 10ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 14/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 9ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 15/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 9ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 16/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 9ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 17/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 9ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 18/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 9ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Batchsize: 256\n",
      "Starting with epoch: 18\n",
      "Epoch 19/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 15ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 20/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 15ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 21/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 22/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 23/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 24/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Batchsize: 512\n",
      "Starting with epoch: 24\n",
      "Epoch 25/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 30ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 26/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 30ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 27/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 30ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 28/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 29ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 29/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 30ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 30/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 30ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "Best thresholds: t1=-0.5146, t2=0.5789, Accuracy: 0.9978\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pocke\\miniconda3\\envs\\speed\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.1960 - val_accuracy: 0.9983 - val_loss: 0.0099\n",
      "Epoch 2/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9977 - loss: 0.0124 - val_accuracy: 0.9983 - val_loss: 0.0086\n",
      "Epoch 3/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0131 - val_accuracy: 0.9983 - val_loss: 0.0084\n",
      "Epoch 4/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9976 - loss: 0.0113 - val_accuracy: 0.9983 - val_loss: 0.0082\n",
      "Epoch 5/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9976 - loss: 0.0116 - val_accuracy: 0.9984 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0118 - val_accuracy: 0.9985 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0124 - val_accuracy: 0.9984 - val_loss: 0.0083\n",
      "Epoch 8/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9976 - loss: 0.0119 - val_accuracy: 0.9986 - val_loss: 0.0078\n",
      "Epoch 9/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0107 - val_accuracy: 0.9985 - val_loss: 0.0081\n",
      "Epoch 10/10\n",
      "\u001b[1m2657/2657\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0120 - val_accuracy: 0.9984 - val_loss: 0.0078\n",
      "\n",
      "Training classification model for KPK\n",
      "Batchsize: 32\n",
      "Starting with epoch: 0\n",
      "Epoch 1/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m795s\u001b[0m 7ms/step - accuracy: 0.9435 - loss: 0.1410 - val_accuracy: 0.9777 - val_loss: 0.0550\n",
      "Epoch 2/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m808s\u001b[0m 7ms/step - accuracy: 0.9770 - loss: 0.0572 - val_accuracy: 0.9812 - val_loss: 0.0461\n",
      "Epoch 3/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m922s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.0475 - val_accuracy: 0.9840 - val_loss: 0.0410\n",
      "Epoch 4/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m926s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.0427 - val_accuracy: 0.9825 - val_loss: 0.0470\n",
      "Epoch 5/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m981s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.0401 - val_accuracy: 0.9861 - val_loss: 0.0350\n",
      "Epoch 6/6\n",
      "\u001b[1m119532/119532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1047s\u001b[0m 9ms/step - accuracy: 0.9852 - loss: 0.0378 - val_accuracy: 0.9864 - val_loss: 0.0350\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Batchsize: 64\n",
      "Starting with epoch: 6\n",
      "Epoch 7/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 12ms/step - accuracy: 0.9884 - loss: 0.0292 - val_accuracy: 0.9885 - val_loss: 0.0299\n",
      "Epoch 8/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0269 - val_accuracy: 0.9895 - val_loss: 0.0259\n",
      "Epoch 9/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0256 - val_accuracy: 0.9895 - val_loss: 0.0263\n",
      "Epoch 10/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0247 - val_accuracy: 0.9902 - val_loss: 0.0245\n",
      "Epoch 11/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 13ms/step - accuracy: 0.9909 - loss: 0.0236 - val_accuracy: 0.9891 - val_loss: 0.0290\n",
      "Epoch 12/12\n",
      "\u001b[1m59766/59766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 14ms/step - accuracy: 0.9911 - loss: 0.0230 - val_accuracy: 0.9908 - val_loss: 0.0239\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Batchsize: 128\n",
      "Starting with epoch: 12\n",
      "Epoch 13/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 22ms/step - accuracy: 0.9931 - loss: 0.0178 - val_accuracy: 0.9922 - val_loss: 0.0204\n",
      "Epoch 14/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 22ms/step - accuracy: 0.9936 - loss: 0.0164 - val_accuracy: 0.9925 - val_loss: 0.0193\n",
      "Epoch 15/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 22ms/step - accuracy: 0.9939 - loss: 0.0157 - val_accuracy: 0.9927 - val_loss: 0.0196\n",
      "Epoch 16/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 23ms/step - accuracy: 0.9942 - loss: 0.0153 - val_accuracy: 0.9928 - val_loss: 0.0183\n",
      "Epoch 17/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 23ms/step - accuracy: 0.9944 - loss: 0.0145 - val_accuracy: 0.9928 - val_loss: 0.0185\n",
      "Epoch 18/18\n",
      "\u001b[1m29883/29883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 23ms/step - accuracy: 0.9945 - loss: 0.0144 - val_accuracy: 0.9935 - val_loss: 0.0173\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Batchsize: 256\n",
      "Starting with epoch: 18\n",
      "Epoch 19/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m656s\u001b[0m 44ms/step - accuracy: 0.9959 - loss: 0.0108 - val_accuracy: 0.9940 - val_loss: 0.0171\n",
      "Epoch 20/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 41ms/step - accuracy: 0.9961 - loss: 0.0102 - val_accuracy: 0.9939 - val_loss: 0.0169\n",
      "Epoch 21/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 42ms/step - accuracy: 0.9963 - loss: 0.0097 - val_accuracy: 0.9946 - val_loss: 0.0144\n",
      "Epoch 22/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 42ms/step - accuracy: 0.9965 - loss: 0.0092 - val_accuracy: 0.9943 - val_loss: 0.0156\n",
      "Epoch 23/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 43ms/step - accuracy: 0.9966 - loss: 0.0090 - val_accuracy: 0.9947 - val_loss: 0.0149\n",
      "Epoch 24/24\n",
      "\u001b[1m14942/14942\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 43ms/step - accuracy: 0.9967 - loss: 0.0088 - val_accuracy: 0.9950 - val_loss: 0.0139\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "Batchsize: 512\n",
      "Starting with epoch: 24\n",
      "Epoch 25/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 84ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.9953 - val_loss: 0.0138\n",
      "Epoch 26/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 83ms/step - accuracy: 0.9977 - loss: 0.0062 - val_accuracy: 0.9951 - val_loss: 0.0153\n",
      "Epoch 27/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 85ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.9956 - val_loss: 0.0135\n",
      "Epoch 28/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m647s\u001b[0m 87ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.9957 - val_loss: 0.0132\n",
      "Epoch 29/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 88ms/step - accuracy: 0.9980 - loss: 0.0054 - val_accuracy: 0.9957 - val_loss: 0.0136\n",
      "Epoch 30/30\n",
      "\u001b[1m7471/7471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 90ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9955 - val_loss: 0.0142\n",
      "Restoring model weights from the end of the best epoch: 28.\n"
     ]
    }
   ],
   "source": [
    "endgames = ['KRK', 'KQKR', 'KPKR', 'KPK']\n",
    "threshold_config = {}\n",
    "model_types = [\n",
    "    (\"single\", create_single_input_model),  # (name, create_func)\n",
    "    (\"regression\", lambda n: create_pairwise_model(\"Regression\", n)),\n",
    "    (\"classification\", lambda n: create_pairwise_model(\"Classification\", n)),\n",
    "]\n",
    "\n",
    "for endgame in endgames:\n",
    "\n",
    "    print(f\"Processing endgame: {endgame}\")\n",
    "\n",
    "    #Load the data\n",
    "    data = np.load(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\DataBase\\{endgame}_position_train_val_2C.npz\")\n",
    "    positions, dtm_values = data[\"X\"], data[\"y\"]\n",
    "    print(f\"Loaded {endgame} data with {dtm_values.shape[0]} samples\")\n",
    "\n",
    "    pairs_data = np.load(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Database\\{endgame}_pairs_train_val_2C.npz\")\n",
    "    X1, X2, y = pairs_data[\"X1\"], pairs_data[\"X2\"], pairs_data[\"y\"]\n",
    "    print(f\"Loaded {endgame} pairs data with {y.shape[0]} samples\")\n",
    "\n",
    "    for model_name, create_func in model_types:\n",
    "        #Help: Check if model already exists\n",
    "        model_path = f\"C:/SPEICHER/Bachelor_Thesis/Experiments/Models/{endgame}_model_{model_name}_2C.keras\"\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Skipping {model_name}, already trained.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nTraining {model_name} model for {endgame}\")\n",
    "\n",
    "        # Create model\n",
    "        model = create_func(positions.shape[1]) #Help: [1]\n",
    "        # model.summary()\n",
    "\n",
    "        #Help: Maybe different mapping\n",
    "        y_trans = np.where(y==1, -1, np.where(y==2, 1, 0))  # -1 = pos1 better, 0 = roughly equal, 1 = pos2 better\n",
    "\n",
    "        # Choose inputs\n",
    "        if model_name == \"single\":\n",
    "            model, history = training(model, positions, dtm_values)\n",
    "        elif model_name == \"regression\":\n",
    "            model, history = training(model, [X1, X2], y_trans)\n",
    "        else:\n",
    "            model, history = training(model, [X1, X2], y, acc=True)\n",
    "\n",
    "        # Save model and history\n",
    "        model.save(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Models\\{endgame}_model_{model_name}_2C.keras\")\n",
    "        with open(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Histories\\{endgame}_history_{model_name}_2C.pkl\", \"wb\") as f:\n",
    "            pickle.dump(history, f)\n",
    "\n",
    "        # Post-processing for single-input model\n",
    "        if model_name == \"single\":\n",
    "            # Predictions\n",
    "            y1_pred = model.predict(X1[:100000])\n",
    "            y2_pred = model.predict(X2[:100000])\n",
    "            y_pred_comb = np.hstack([y1_pred, y2_pred])\n",
    "\n",
    "            # Threshold method\n",
    "            best_threshold, best_accuracy = find_best_threshold_v1(y1_pred, y2_pred, y[:100000])\n",
    "            print(f\"Best threshold: {best_threshold:.4f}, Accuracy: {best_accuracy:.4f}\")\n",
    "            threshold_config.setdefault(endgame, {})[model_name] = {\"threshold1\": float(best_threshold),\"threshold2\": float(0)}\n",
    "            # Nerual Network\n",
    "            model = create_post_nn(2)\n",
    "            # model.summary()\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "            model.fit(y_pred_comb, y[:100000], epochs=10, batch_size=32, validation_split=0.15, callbacks=[early_stopping])\n",
    "            model.save(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Models\\{endgame}_model_pro_{model_name}_2C.keras\")\n",
    "\n",
    "        elif model_name == \"regression\":\n",
    "            # Predictions\n",
    "            y_pred = model.predict([X1[:100000], X2[:100000]])\n",
    "            \n",
    "            # Threshold method\n",
    "            best_t1, best_t2, best_acc = find_best_thresholds_v2(y_pred, y[:100000])\n",
    "            print(f\"Best thresholds: t1={best_t1:.4f}, t2={best_t2:.4f}, Accuracy: {best_acc:.4f}\")\n",
    "            threshold_config.setdefault(endgame, {})[model_name] = {\"threshold1\": float(best_t1),\"threshold2\": float(best_t2)}\n",
    "            # Nerual Network\n",
    "            model = create_post_nn(1)\n",
    "            # model.summary()\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "            model.fit(y_pred, y[:100000], epochs=10, batch_size=32, validation_split=0.15, callbacks=[early_stopping])\n",
    "            model.save(rf\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Models\\{endgame}_model_pro_{model_name}_2C.keras\")\n",
    "\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "    with open(r\"C:\\SPEICHER\\Bachelor_Thesis\\Experiments\\Configs\\thresholds_2C.json\", \"w\") as f:\n",
    "        json.dump(threshold_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820c742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
